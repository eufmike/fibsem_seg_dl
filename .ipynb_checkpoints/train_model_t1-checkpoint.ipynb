{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "Keras on Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, glob, shutil\n",
    "import os, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from core.imageprep import random_crop, crop_generator, random_crop_batch\n",
    "from core.models import UNet\n",
    "from imutils import paths\n",
    "import itertools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "print(\"Load Images...\")\n",
    "# on mac\n",
    "# path = \"/Volumes/LaCie_DataStorage/PerlmutterData/\"\n",
    "\n",
    "# on Window PC \n",
    "path = \"D:/PerlmutterData/\"\n",
    "imgdir = \"training/cell_membrane/prepdata\"\n",
    "imgpath = os.path.join(path, imgdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath_all = list(paths.list_images(path))\n",
    "print(imgpath_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "seed = 100\n",
    "batch_size = 16\n",
    "validation_split = 0.1\n",
    "training_sample_size = len(imgpath_all)\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Image Datagenerator\n",
    "1. create only one datagen\n",
    "2. specify valiation split in datagen argument\n",
    "3. add split data when calling `datagen.flow_from_directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arguments for data generator\n",
    "data_gen_args = dict(\n",
    "                featurewise_center=True,\n",
    "                featurewise_std_normalization=True,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True,\n",
    "                rotation_range=90.,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                shear_range=0.07,\n",
    "                zoom_range=0.2,\n",
    "                validation_split=validation_split, # <- specify validation_split ratio\n",
    "                # fill_mode='constant',\n",
    "                # cval=0.,\n",
    "                # rescale=1.0/255.0,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "label_datagen = ImageDataGenerator(**data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images into generator\n",
    "train_image_generator = image_datagen.flow_from_directory(\n",
    "    os.path.join(imgpath, 'train/images/'),\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='training', # <- define subset as 'training'\n",
    "    seed=seed)\n",
    "\n",
    "train_label_generator = label_datagen.flow_from_directory(\n",
    "    os.path.join(imgpath, 'train/labels'),\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "valid_image_generator = image_datagen.flow_from_directory(\n",
    "    os.path.join(imgpath, 'train/images/'),\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation', # <- define subset as 'validation'\n",
    "    seed=seed)\n",
    "\n",
    "valid_label_generator = label_datagen.flow_from_directory(\n",
    "    os.path.join(imgpath, 'train/labels'),\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge image and label generator\n",
    "train_generator = zip(train_image_generator, train_label_generator)\n",
    "valid_generator = zip(valid_image_generator, valid_label_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# load dependency\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointer\n",
    "# check if the output folder exist. If not, create a folder\n",
    "if not 'model' in os.listdir(path):\n",
    "    os.mkdir(os.path.join(path, 'model'))\n",
    "\n",
    "# set up the checkpointer\n",
    "# save model\n",
    "modelfilename = 'model_' + datetime.now().strftime(\"%Y_%m_%d_%H_%M\") + '.h5'\n",
    "modelfilepath = os.path.join(path, 'model', modelfilename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(modelfilepath, monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate steps_per_epoch\n",
    "steps_per_epoch = training_sample_size * (1-validation_split) // batch_size\n",
    "print(\"Steps per epoch: {}\".format(steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model\n",
    "unetmodel = UNet([IMG_HEIGHT, IMG_WIDTH])\n",
    "\n",
    "# train the model\n",
    "unetmodel.fit_generator(generator=train_generator, \n",
    "                    validation_data = valid_generator,\n",
    "                    validation_steps = 20,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    epochs = 500, \n",
    "                    verbose=1, \n",
    "                    callbacks=[checkpointer]\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
