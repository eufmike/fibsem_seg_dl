{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "Keras on Tensorflow\n",
    "\n",
    "trained from  /2020_01_24/model_2020_01_24_16_02.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import itertools\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from core.imageprep import dir_checker, random_crop, crop_generator, random_crop_batch\n",
    "from core.models import UNet, UNet_hp, vanilla_unet, vanilla_unet_nodrop\n",
    "from core.metrics import iou_coef, dice_coef\n",
    "\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython import get_ipython\n",
    "# %load_ext autoreload\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "# %autoreload 2\n",
    "get_ipython().run_line_magic('autoreload', '2')\n",
    "# %load_ext tensorboard\n",
    "get_ipython().run_line_magic('load_ext', 'tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wucci_admin\\\\Anaconda3\\\\envs\\\\tfdl02\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Images...\n",
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2020_01_23_09_51_20x\n",
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2020_01_23_09_51_20x\\images\n",
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2020_01_23_09_51_20x\\labels\n",
      "logs exists in D:PerlmutterData\n",
      "fit exists in D:PerlmutterData\\logs\n",
      "model exists in D:PerlmutterData\\logs\n",
      "pars exists in D:PerlmutterData\\logs\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "print(\"Load Images...\")\n",
    "# on mac\n",
    "# path = \"/Volumes/LaCie_DataStorage/PerlmutterData/\"\n",
    "\n",
    "# on Window PC \n",
    "path = os.path.join('D:', 'PerlmutterData')\n",
    "\n",
    "# input set\n",
    "crop_input_set = '2020_01_23_09_51_20x'\n",
    "# crop_input_set = '2020_01_30_11_24_1x' # small training set\n",
    "\n",
    "imginput = os.path.join('dl_seg_project_raw', 'data_crop', crop_input_set,)\n",
    "imgpath = os.path.join(path, imginput)\n",
    "\n",
    "print(imgpath)\n",
    "\n",
    "img_dir = os.path.join(imgpath, 'images')\n",
    "label_dir = os.path.join(imgpath, 'labels')\n",
    "print(img_dir)\n",
    "print(label_dir)\n",
    "\n",
    "# check if the output folder exist. If not, create a folder\n",
    "dir_checker('logs', path)\n",
    "path_logs = os.path.join(path, 'logs')\n",
    "dir_checker('fit', path_logs)\n",
    "dir_checker('model', path_logs)\n",
    "dir_checker('pars', path_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Print the first file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2020_01_23_09_51_20x\\images\\nucleus\\0001.tif\n"
     ]
    }
   ],
   "source": [
    "imgpath_all = list(paths.list_images(imgpath))\n",
    "print(imgpath_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Create Image Datagenerator\n",
    " 1. create only one datagen\n",
    " 2. specify valiation split in datagen argument\n",
    " 3. add split data when calling `datagen.flow_from_directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "date =  datetime.now().strftime(\"%Y_%m_%d\")\n",
    "seed = 102\n",
    "batch_size = 16\n",
    "epoch = 500\n",
    "validation_steps = 20\n",
    "validation_split = 0.3\n",
    "training_sample_size = len(imgpath_all)\n",
    "IMG_HEIGHT = None\n",
    "IMG_WIDTH = None\n",
    "classes = ['cell_membrane', 'nucleus', 'autophagosome']\n",
    "inputclass = [classes[1]]\n",
    "learning_rate = 1e-5\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = ['accuracy', iou_coef, dice_coef]\n",
    "\n",
    "metrics_name = []\n",
    "for f in metrics:\n",
    "    if callable(f):\n",
    "        metrics_name.append(f.__name__)\n",
    "    else:\n",
    "        metrics_name.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nucleus exists in D:PerlmutterData\\logs\\pars\n",
      "2020_02_04 exists in D:PerlmutterData\\logs\\pars\\nucleus\n",
      "{'IMG_HEIGHT': None,\n",
      " 'IMG_WIDTH': None,\n",
      " 'batch_size': 16,\n",
      " 'classes': ['cell_membrane', 'nucleus', 'autophagosome'],\n",
      " 'crop_input_set': '2020_01_23_09_51_20x',\n",
      " 'data_gen_img_args': {'height_shift_range': 0.1,\n",
      "                       'horizontal_flip': True,\n",
      "                       'rescale': 0.00392156862745098,\n",
      "                       'rotation_range': 90.0,\n",
      "                       'shear_range': 0.07,\n",
      "                       'validation_split': 0.3,\n",
      "                       'vertical_flip': True,\n",
      "                       'width_shift_range': 0.1,\n",
      "                       'zoom_range': 0.2},\n",
      " 'data_gen_label_args': {'height_shift_range': 0.1,\n",
      "                         'horizontal_flip': True,\n",
      "                         'rescale': 0.00392156862745098,\n",
      "                         'rotation_range': 90.0,\n",
      "                         'shear_range': 0.07,\n",
      "                         'validation_split': 0.3,\n",
      "                         'vertical_flip': True,\n",
      "                         'width_shift_range': 0.1,\n",
      "                         'zoom_range': 0.2},\n",
      " 'date': '2020_02_04',\n",
      " 'epoch': 500,\n",
      " 'inputclass': ['nucleus'],\n",
      " 'learning_rate': 1e-05,\n",
      " 'loss': 'binary_crossentropy',\n",
      " 'metrics_name': ['accuracy', 'iou_coef', 'dice_coef'],\n",
      " 'seed': 102,\n",
      " 'timestamp': '2020_02_04_16_15',\n",
      " 'training_sample_size': 13240,\n",
      " 'validation_split': 0.3,\n",
      " 'validation_steps': 20}\n"
     ]
    }
   ],
   "source": [
    "# create arguments for data generator\n",
    "data_gen_img_args = dict(\n",
    "                # featurewise_center = True,\n",
    "                # featurewise_std_normalization = True,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True,\n",
    "                rotation_range = 90.,\n",
    "                width_shift_range = 0.1,\n",
    "                height_shift_range = 0.1,\n",
    "                shear_range = 0.07,\n",
    "                zoom_range = 0.2,\n",
    "                validation_split = validation_split, # <- specify validation_split ratio\n",
    "                # fill_mode='constant',\n",
    "                # cval=0.,\n",
    "                rescale=1.0/255.0,\n",
    "                )\n",
    "\n",
    "data_gen_label_args = dict(\n",
    "                # featurewise_center=True,\n",
    "                # featurewise_std_normalization=True,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True,\n",
    "                rotation_range = 90.,\n",
    "                width_shift_range = 0.1,\n",
    "                height_shift_range = 0.1,\n",
    "                shear_range = 0.07,\n",
    "                zoom_range = 0.2,\n",
    "                validation_split = validation_split, # <- specify validation_split ratio\n",
    "                # fill_mode='constant',\n",
    "                # cval=0.,\n",
    "                # rescale=1.0/255.0,\n",
    "                rescale=1.0/255.0,\n",
    "                )\n",
    "\n",
    "# create parameter\n",
    "pars = dict(\n",
    "                # basic information\n",
    "                timestamp = timestamp,\n",
    "                date = date,\n",
    "                seed = seed,\n",
    "                batch_size = batch_size,\n",
    "                \n",
    "                # Data generator\n",
    "                crop_input_set = crop_input_set,\n",
    "                validation_steps = validation_steps,\n",
    "                validation_split = validation_split,\n",
    "                training_sample_size = training_sample_size,\n",
    "                \n",
    "                # training class\n",
    "                classes = classes,\n",
    "                inputclass = inputclass,\n",
    "    \n",
    "                # add datagen args\n",
    "                data_gen_img_args = data_gen_img_args,\n",
    "                data_gen_label_args = data_gen_label_args,\n",
    "                \n",
    "                # Build model\n",
    "                IMG_HEIGHT = IMG_HEIGHT,\n",
    "                IMG_WIDTH = IMG_WIDTH,\n",
    "                epoch = epoch, \n",
    "                loss = loss,\n",
    "                metrics_name = metrics_name,\n",
    "                learning_rate = learning_rate,\n",
    "                )\n",
    "\n",
    "# save parameter\n",
    "path_pars = os.path.join(path_logs, 'pars')\n",
    "dir_checker(inputclass[0], path_pars)\n",
    "dir_checker(date, os.path.join(path_pars, inputclass[0]))\n",
    "\n",
    "pprint(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:PerlmutterData\\logs\\pars\\nucleus\\2020_02_04\\pars_2020_02_04_16_15.json\n"
     ]
    }
   ],
   "source": [
    "par_file_dir = os.path.join(path_pars, inputclass[0], date, 'pars_' + timestamp + '.json')\n",
    "print(par_file_dir)\n",
    "\n",
    "with open(par_file_dir, 'w') as outfile:\n",
    "    json.dump(pars, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator\n",
    "image_datagen = ImageDataGenerator(**data_gen_img_args)\n",
    "label_datagen = ImageDataGenerator(**data_gen_label_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4634 images belonging to 1 classes.\n",
      "Found 4634 images belonging to 1 classes.\n",
      "Found 1986 images belonging to 1 classes.\n",
      "Found 1986 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# load images into generator\n",
    "train_image_generator = image_datagen.flow_from_directory(\n",
    "    img_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='training', # <- define subset as 'training'\n",
    "    seed=seed)\n",
    "\n",
    "train_label_generator = label_datagen.flow_from_directory(\n",
    "    label_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "valid_image_generator = image_datagen.flow_from_directory(\n",
    "    img_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation', # <- define subset as 'validation'\n",
    "    seed=seed)\n",
    "\n",
    "valid_label_generator = label_datagen.flow_from_directory(\n",
    "    label_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge image and label generator\n",
    "def combine_generator(gen1, gen2):\n",
    "    while True:\n",
    "        yield(gen1.next(), gen2.next()) \n",
    "train_generator = combine_generator(train_image_generator, train_label_generator)\n",
    "valid_generator = combine_generator(valid_image_generator, valid_label_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_generator = zip(train_image_generator, train_label_generator)\\nvalid_generator = zip(valid_image_generator, valid_label_generator)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_generator = zip(train_image_generator, train_label_generator)\n",
    "valid_generator = zip(valid_image_generator, valid_label_generator)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nucleus exists in D:PerlmutterData\\logs\\model\n",
      "2020_02_04 exists in D:PerlmutterData\\logs\\model\\nucleus\n",
      "nucleus exists in D:PerlmutterData\\logs\\fit\n",
      "2020_02_04 exists in D:PerlmutterData\\logs\\fit\\nucleus\n"
     ]
    }
   ],
   "source": [
    "# checkpoint\n",
    "modelfilename = 'model_' + timestamp + '.h5'\n",
    "dir_checker(inputclass[0], os.path.join(path_logs, 'model'))\n",
    "dir_checker(date, os.path.join(path_logs, 'model', inputclass[0]))\n",
    "modelfile_path = os.path.join(path_logs, 'model', inputclass[0], date, modelfilename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = modelfile_path, \n",
    "                               monitor = 'val_loss', \n",
    "                               mode = 'min', \n",
    "                               verbose = 1, \n",
    "                               save_best_only = True)\n",
    "\n",
    "# early stopping \n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                           patience=8,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4)\n",
    "\n",
    "# learning rate adjustment\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss',\n",
    "                    factor=0.1,\n",
    "                    patience=4,\n",
    "                    verbose=1,\n",
    "                    min_delta=1e-4)\n",
    "\n",
    "# tensorboard\n",
    "from tensorflow.summary import create_file_writer\n",
    "\n",
    "dir_checker(inputclass[0], os.path.join(path_logs, 'fit'))\n",
    "dir_checker(date, os.path.join(path_logs, 'fit', inputclass[0]))\n",
    "logdir = os.path.join(path_logs, 'fit', inputclass[0], date, timestamp)\n",
    "\n",
    "file_writer = create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "metrics = ['accuracy', iou_coef, dice_coef]\n",
    "\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir = logdir, \n",
    "                                   profile_batch = 0, \n",
    "                                   update_freq= 500,\n",
    "                                   histogram_freq = 1\n",
    "                                   )\n",
    "\n",
    "# compile callbacks\n",
    "# callbacks = [checkpointer, tensorboard_callback, early_stopping, reduceLR]\n",
    "callbacks = [checkpointer, tensorboard_callback, reduceLR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 579.0\n"
     ]
    }
   ],
   "source": [
    "# calculate steps_per_epoch\n",
    "steps_per_epoch = training_sample_size * (1 - validation_split) // batch_size\n",
    "print(\"Steps per epoch: {}\".format(steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_04\\2020_02_04_16_15\n"
     ]
    }
   ],
   "source": [
    "print(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# prepare the model\\nunetmodel = UNet(shape = (IMG_HEIGHT, IMG_WIDTH), \\n                 lr = learning_rate, \\n                 loss = loss,\\n                 metrics = metrics,\\n                )\\n\\n# train the model\\nunetmodel.fit_generator(\\n                    generator = train_generator, \\n                    validation_data = valid_generator,\\n                    validation_steps = validation_steps,\\n                    steps_per_epoch = steps_per_epoch,\\n                    epochs = epoch,  \\n                    callbacks = callbacks,\\n                    verbose = 1, \\n                    )\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# prepare the model\n",
    "unetmodel = UNet(shape = (IMG_HEIGHT, IMG_WIDTH), \n",
    "                 lr = learning_rate, \n",
    "                 loss = loss,\n",
    "                 metrics = metrics,\n",
    "                )\n",
    "\n",
    "# train the model\n",
    "unetmodel.fit_generator(\n",
    "                    generator = train_generator, \n",
    "                    validation_data = valid_generator,\n",
    "                    validation_steps = validation_steps,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    epochs = epoch,  \n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1, \n",
    "                    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 6 36928       conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 6 0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 1 73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 1 147584      conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, None, None, 1 0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 2 295168      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 2 590080      conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, None, None, 2 0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 5 1180160     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 5 2359808     conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, None, None, 5 0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, None, 5 0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 4719616     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, None, 1 0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 9438208     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, None, None, 1 0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, None, 1 0           up_sampling2d_5[0][0]            \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 5 7078400     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 5 2359808     conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, None, None, 5 0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, None, 7 0           up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 2 1769728     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 2 590080      conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, None, None, 2 0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, None, 3 0           up_sampling2d_7[0][0]            \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 442496      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 147584      conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, None, None, 1 0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, None, None, 1 0           up_sampling2d_8[0][0]            \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 6 110656      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 6 36928       conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 65          conv2d_40[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,377,793\n",
      "Trainable params: 31,377,793\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/579 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.9518 - iou_coef: 0.3022 - dice_coef: 0.3289\n",
      "Epoch 00001: val_loss improved from inf to 0.32404, saving model to D:PerlmutterData\\logs\\model\\nucleus\\2020_02_04\\model_2020_02_04_16_15.h5\n",
      "579/579 [==============================] - 508s 878ms/step - loss: 0.1609 - accuracy: 0.9517 - iou_coef: 0.3020 - dice_coef: 0.3286 - val_loss: 0.3240 - val_accuracy: 0.9122 - val_iou_coef: 0.4174 - val_dice_coef: 0.4502\n",
      "Epoch 2/500\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1532 - accuracy: 0.9534 - iou_coef: 0.3044 - dice_coef: 0.3308\n",
      "Epoch 00002: val_loss improved from 0.32404 to 0.19213, saving model to D:PerlmutterData\\logs\\model\\nucleus\\2020_02_04\\model_2020_02_04_16_15.h5\n",
      "579/579 [==============================] - 499s 863ms/step - loss: 0.1535 - accuracy: 0.9534 - iou_coef: 0.3046 - dice_coef: 0.3310 - val_loss: 0.1921 - val_accuracy: 0.9312 - val_iou_coef: 0.4227 - val_dice_coef: 0.4682\n",
      "Epoch 3/500\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1510 - accuracy: 0.9538 - iou_coef: 0.3060 - dice_coef: 0.3324\n",
      "Epoch 00003: val_loss did not improve from 0.19213\n",
      "579/579 [==============================] - 499s 861ms/step - loss: 0.1512 - accuracy: 0.9538 - iou_coef: 0.3061 - dice_coef: 0.3325 - val_loss: 0.2061 - val_accuracy: 0.9386 - val_iou_coef: 0.4634 - val_dice_coef: 0.5092\n",
      "Epoch 4/500\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1461 - accuracy: 0.9547 - iou_coef: 0.3081 - dice_coef: 0.3335\n",
      "Epoch 00004: val_loss improved from 0.19213 to 0.16339, saving model to D:PerlmutterData\\logs\\model\\nucleus\\2020_02_04\\model_2020_02_04_16_15.h5\n",
      "579/579 [==============================] - 500s 863ms/step - loss: 0.1461 - accuracy: 0.9548 - iou_coef: 0.3083 - dice_coef: 0.3337 - val_loss: 0.1634 - val_accuracy: 0.9429 - val_iou_coef: 0.4134 - val_dice_coef: 0.4561\n",
      "Epoch 5/500\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1425 - accuracy: 0.9553 - iou_coef: 0.3107 - dice_coef: 0.3356\n",
      "Epoch 00005: val_loss did not improve from 0.16339\n",
      "579/579 [==============================] - 498s 861ms/step - loss: 0.1423 - accuracy: 0.9554 - iou_coef: 0.3105 - dice_coef: 0.3353 - val_loss: 0.2197 - val_accuracy: 0.9234 - val_iou_coef: 0.4430 - val_dice_coef: 0.4848\n",
      "Epoch 6/500\n",
      "536/579 [==========================>...] - ETA: 36s - loss: 0.1391 - accuracy: 0.9566 - iou_coef: 0.3115 - dice_coef: 0.3356"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7a3078aa3419>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                     )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1985\u001b[0m     return backend.resize_images(\n\u001b[0;32m   1986\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1987\u001b[1;33m         interpolation=self.interpolation)\n\u001b[0m\u001b[0;32m   1988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1989\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mresize_images\u001b[1;34m(x, height_factor, width_factor, data_format, interpolation)\u001b[0m\n\u001b[0;32m   2796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2797\u001b[0m   \u001b[0moriginal_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2798\u001b[1;33m   \u001b[0mnew_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcols\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2799\u001b[0m   new_shape *= constant_op.constant(\n\u001b[0;32m   2800\u001b[0m       np.array([height_factor, width_factor], dtype='int32'))\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, name, out_type)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m   \"\"\"\n\u001b[1;32m--> 458\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[1;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdl02\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m   8959\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   8960\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Shape\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8961\u001b[1;33m         name, _ctx._post_execution_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[0;32m   8962\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8963\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "path_model = os.path.join(os.path.join(path_logs, 'fit', inputclass[0]), '2020_02_03', '2020_02_03_09_07', 'run-2', 'model', 'model_2020_02_03_09_07.h5')\n",
    "\n",
    "dropout = 0.7\n",
    "num_layers = 4\n",
    "\n",
    "unetmodel = vanilla_unet_nodrop(\n",
    "                            shape = (IMG_HEIGHT, IMG_WIDTH), \n",
    "                            dropout = dropout, \n",
    "                            num_layers = num_layers, \n",
    "                            lr = learning_rate, \n",
    "                            loss = loss,\n",
    "                            metrics = metrics,\n",
    "                            summary = True,\n",
    "                            use_batch_norm = False\n",
    "                           )\n",
    "\n",
    "unetmodel.load_weights(path_model)\n",
    "\n",
    "unetmodel.fit_generator(\n",
    "                    generator = train_generator, \n",
    "                    validation_data = valid_generator,\n",
    "                    validation_steps = validation_steps,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    epochs = epoch,  \n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1, \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "tfdl02",
   "language": "python",
   "name": "tfdl02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
