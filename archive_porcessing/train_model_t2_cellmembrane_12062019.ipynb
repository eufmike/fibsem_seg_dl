{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wucci_admin\\\\Anaconda3\\\\envs\\\\tfdl02\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntry:\\n\\tos.chdir(os.path.join(os.getcwd(), '../../../../../../var/folders/lx/703nk8wx7vb585ttwyxk_1lr0000gn/T'))\\n\\tprint(os.getcwd())\\nexcept:\\n\\tpass\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ms-python.python added\n",
    "import os\n",
    "'''\n",
    "try:\n",
    "\tos.chdir(os.path.join(os.getcwd(), '../../../../../../var/folders/lx/703nk8wx7vb585ttwyxk_1lr0000gn/T'))\n",
    "\tprint(os.getcwd())\n",
    "except:\n",
    "\tpass\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Training Model\n",
    " Keras on Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, glob, shutil\n",
    "import os, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from core.imageprep import random_crop, crop_generator, random_crop_batch\n",
    "from core.models import UNet\n",
    "\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Images...\n",
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2019_12_06_17_06\n",
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2019_12_06_17_06\\images\n",
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2019_12_06_17_06\\labels\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "print(\"Load Images...\")\n",
    "# on mac\n",
    "# path = \"/Volumes/LaCie_DataStorage/PerlmutterData/\"\n",
    "\n",
    "# on Window PC \n",
    "path = os.path.join('D:', 'PerlmutterData')\n",
    "imginput = os.path.join('dl_seg_project_raw', 'data_crop', '2019_12_06_17_06',)\n",
    "imgpath = os.path.join(path, imginput)\n",
    "\n",
    "print(imgpath)\n",
    "\n",
    "img_dir = os.path.join(imgpath, 'images')\n",
    "label_dir = os.path.join(imgpath, 'labels')\n",
    "print(img_dir)\n",
    "print(label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Print the first file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2019_12_06_17_06\\images\\autophagosome\\0001.tif\n"
     ]
    }
   ],
   "source": [
    "imgpath_all = list(paths.list_images(imgpath))\n",
    "print(imgpath_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Create Image Datagenerator\n",
    " 1. create only one datagen\n",
    " 2. specify valiation split in datagen argument\n",
    " 3. add split data when calling `datagen.flow_from_directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "seed = 100\n",
    "batch_size = 16\n",
    "epoch = 500\n",
    "validation_steps = 20\n",
    "validation_split = 0.1\n",
    "training_sample_size = len(imgpath_all)\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "classes = ['cell_membrane', 'nucleus', 'autophagosome']\n",
    "inputclass = [classes[0]]\n",
    "learning_rate = 1e-5\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arguments for data generator\n",
    "data_gen_img_args = dict(\n",
    "                # featurewise_center = True,\n",
    "                # featurewise_std_normalization = True,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True,\n",
    "                rotation_range = 90.,\n",
    "                width_shift_range = 0.1,\n",
    "                height_shift_range = 0.1,\n",
    "                shear_range = 0.07,\n",
    "                zoom_range = 0.2,\n",
    "                validation_split = validation_split, # <- specify validation_split ratio\n",
    "                # fill_mode='constant',\n",
    "                # cval=0.,\n",
    "                rescale=1.0/255.0,\n",
    "                )\n",
    "\n",
    "data_gen_label_args = dict(\n",
    "                # featurewise_center=True,\n",
    "                # featurewise_std_normalization=True,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True,\n",
    "                rotation_range = 90.,\n",
    "                width_shift_range = 0.1,\n",
    "                height_shift_range = 0.1,\n",
    "                shear_range = 0.07,\n",
    "                zoom_range = 0.2,\n",
    "                validation_split = validation_split, # <- specify validation_split ratio\n",
    "                # fill_mode='constant',\n",
    "                # cval=0.,\n",
    "                # rescale=1.0/255.0,\n",
    "                rescale=1.0/255.0,\n",
    "                )\n",
    "\n",
    "# create parameter\n",
    "pars = dict(\n",
    "                timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\"),\n",
    "                seed = seed,\n",
    "                batch_size = batch_size,\n",
    "                epoch = epoch,\n",
    "                validation_steps = validation_steps,\n",
    "                validation_split = validation_split,\n",
    "                training_sample_size = training_sample_size,\n",
    "                IMG_HEIGHT = IMG_HEIGHT,\n",
    "                IMG_WIDTH = IMG_WIDTH,\n",
    "                # training class\n",
    "                classes = classes,\n",
    "                inputclass = inputclass,\n",
    "                # add datagen args\n",
    "                data_gen_img_args = data_gen_img_args,\n",
    "                data_gen_label_args = data_gen_label_args,\n",
    "                # hyper parameter\n",
    "                loss = loss,\n",
    "                metrics = metrics,\n",
    "                learning_rate = learning_rate,\n",
    "                )\n",
    "\n",
    "# save parameter\n",
    "if not 'pars' in os.listdir(path):\n",
    "    os.mkdir(os.path.join(path, 'pars'))\n",
    "    \n",
    "jsonpath = os.path.join(path, 'pars')\n",
    "\n",
    "with open(os.path.join(jsonpath, 'pars_' + timestamp + '.json'), 'w') as outfile:\n",
    "    json.dump(pars, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator\n",
    "image_datagen = ImageDataGenerator(**data_gen_img_args)\n",
    "label_datagen = ImageDataGenerator(**data_gen_label_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8100 images belonging to 1 classes.\n",
      "Found 8100 images belonging to 1 classes.\n",
      "Found 900 images belonging to 1 classes.\n",
      "Found 900 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# load images into generator\n",
    "train_image_generator = image_datagen.flow_from_directory(\n",
    "    img_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='training', # <- define subset as 'training'\n",
    "    seed=seed)\n",
    "\n",
    "train_label_generator = label_datagen.flow_from_directory(\n",
    "    label_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "valid_image_generator = image_datagen.flow_from_directory(\n",
    "    img_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation', # <- define subset as 'validation'\n",
    "    seed=seed)\n",
    "\n",
    "valid_label_generator = label_datagen.flow_from_directory(\n",
    "    label_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge image and label generator\n",
    "def combine_generator(gen1, gen2):\n",
    "    while True:\n",
    "        yield(gen1.next(), gen2.next()) \n",
    "train_generator = combine_generator(train_image_generator, train_label_generator)\n",
    "valid_generator = combine_generator(valid_image_generator, valid_label_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_generator = zip(train_image_generator, train_label_generator)\\nvalid_generator = zip(valid_image_generator, valid_label_generator)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_generator = zip(train_image_generator, train_label_generator)\n",
    "valid_generator = zip(valid_image_generator, valid_label_generator)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointer\n",
    "# check if the output folder exist. If not, create a folder\n",
    "if not 'model' in os.listdir(path):\n",
    "    os.mkdir(os.path.join(path, 'model'))\n",
    "\n",
    "if not 'logs' in os.listdir(path):\n",
    "    os.mkdir(os.path.join(path, 'logs'))\n",
    "    os.mkdir(os.path.join(path, 'logs', 'fit'))\n",
    "    \n",
    "# set up the checkpointer\n",
    "# save model\n",
    "modelfilename = 'model_' + timestamp + '.h5'\n",
    "modelfilepath = os.path.join(path, 'model', modelfilename)\n",
    "\n",
    "checkpointer = ModelCheckpoint(modelfilepath, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "log_dir=os.path.join(path, 'logs', 'fit', datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# add tensorboard\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 3043.0\n"
     ]
    }
   ],
   "source": [
    "# calculate steps_per_epoch\n",
    "steps_per_epoch = training_sample_size * (1-validation_split) // batch_size\n",
    "print(\"Steps per epoch: {}\".format(steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 shape: (None, 256, 256, 64)\n",
      "conv1 shape: (None, 256, 256, 64)\n",
      "pool1 shape: (None, 128, 128, 64)\n",
      "conv2 shape: (None, 128, 128, 128)\n",
      "conv2 shape: (None, 128, 128, 128)\n",
      "pool2 shape: (None, 64, 64, 128)\n",
      "conv3 shape: (None, 64, 64, 256)\n",
      "conv3 shape: (None, 64, 64, 256)\n",
      "pool3 shape: (None, 32, 32, 256)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 1024) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1024) 0           dropout[0][0]                    \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 1)  65          conv2d_21[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,030,593\n",
      "Trainable params: 31,030,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0841 - accuracy: 0.9686\n",
      "Epoch 00001: val_loss improved from inf to 0.01990, saving model to D:PerlmutterData\\model\\model_2019_12_06_17_14.h5\n",
      "3043/3043 [==============================] - 2980s 979ms/step - loss: 0.0841 - accuracy: 0.9686 - val_loss: 0.0199 - val_accuracy: 0.9933\n",
      "Epoch 2/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9872\n",
      "Epoch 00002: val_loss did not improve from 0.01990\n",
      "3043/3043 [==============================] - 2980s 979ms/step - loss: 0.0346 - accuracy: 0.9872 - val_loss: 0.0447 - val_accuracy: 0.9866\n",
      "Epoch 3/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9898\n",
      "Epoch 00003: val_loss improved from 0.01990 to 0.01989, saving model to D:PerlmutterData\\model\\model_2019_12_06_17_14.h5\n",
      "3043/3043 [==============================] - 2983s 980ms/step - loss: 0.0269 - accuracy: 0.9898 - val_loss: 0.0199 - val_accuracy: 0.9915\n",
      "Epoch 4/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9915\n",
      "Epoch 00004: val_loss did not improve from 0.01989\n",
      "3043/3043 [==============================] - 2978s 979ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.0307 - val_accuracy: 0.9887\n",
      "Epoch 5/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9922\n",
      "Epoch 00005: val_loss improved from 0.01989 to 0.01266, saving model to D:PerlmutterData\\model\\model_2019_12_06_17_14.h5\n",
      "3043/3043 [==============================] - 2979s 979ms/step - loss: 0.0193 - accuracy: 0.9922 - val_loss: 0.0127 - val_accuracy: 0.9949\n",
      "Epoch 6/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9932\n",
      "Epoch 00006: val_loss improved from 0.01266 to 0.00856, saving model to D:PerlmutterData\\model\\model_2019_12_06_17_14.h5\n",
      "3043/3043 [==============================] - 2980s 979ms/step - loss: 0.0164 - accuracy: 0.9932 - val_loss: 0.0086 - val_accuracy: 0.9958\n",
      "Epoch 7/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9937\n",
      "Epoch 00007: val_loss did not improve from 0.00856\n",
      "3043/3043 [==============================] - 2969s 976ms/step - loss: 0.0147 - accuracy: 0.9937 - val_loss: 0.0107 - val_accuracy: 0.9950\n",
      "Epoch 8/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9940\n",
      "Epoch 00008: val_loss did not improve from 0.00856\n",
      "3043/3043 [==============================] - 2978s 979ms/step - loss: 0.0138 - accuracy: 0.9940 - val_loss: 0.0089 - val_accuracy: 0.9955\n",
      "Epoch 9/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9941\n",
      "Epoch 00009: val_loss did not improve from 0.00856\n",
      "3043/3043 [==============================] - 2971s 976ms/step - loss: 0.0133 - accuracy: 0.9941 - val_loss: 0.0124 - val_accuracy: 0.9943\n",
      "Epoch 10/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9946\n",
      "Epoch 00010: val_loss did not improve from 0.00856\n",
      "3043/3043 [==============================] - 2973s 977ms/step - loss: 0.0119 - accuracy: 0.9946 - val_loss: 0.0098 - val_accuracy: 0.9952\n",
      "Epoch 11/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9945\n",
      "Epoch 00011: val_loss did not improve from 0.00856\n",
      "3043/3043 [==============================] - 2974s 977ms/step - loss: 0.0122 - accuracy: 0.9945 - val_loss: 0.0091 - val_accuracy: 0.9955\n",
      "Epoch 12/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9951\n",
      "Epoch 00012: val_loss did not improve from 0.00856\n",
      "3043/3043 [==============================] - 2969s 976ms/step - loss: 0.0105 - accuracy: 0.9951 - val_loss: 0.0112 - val_accuracy: 0.9946\n",
      "Epoch 13/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9951\n",
      "Epoch 00013: val_loss improved from 0.00856 to 0.00764, saving model to D:PerlmutterData\\model\\model_2019_12_06_17_14.h5\n",
      "3043/3043 [==============================] - 2980s 979ms/step - loss: 0.0103 - accuracy: 0.9951 - val_loss: 0.0076 - val_accuracy: 0.9960\n",
      "Epoch 14/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9945\n",
      "Epoch 00014: val_loss improved from 0.00764 to 0.00648, saving model to D:PerlmutterData\\model\\model_2019_12_06_17_14.h5\n",
      "3043/3043 [==============================] - 2966s 975ms/step - loss: 0.0123 - accuracy: 0.9945 - val_loss: 0.0065 - val_accuracy: 0.9961\n",
      "Epoch 15/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9954\n",
      "Epoch 00015: val_loss did not improve from 0.00648\n",
      "3043/3043 [==============================] - 2973s 977ms/step - loss: 0.0094 - accuracy: 0.9954 - val_loss: 0.0100 - val_accuracy: 0.9954\n",
      "Epoch 16/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9955\n",
      "Epoch 00016: val_loss did not improve from 0.00648\n",
      "3043/3043 [==============================] - 2972s 977ms/step - loss: 0.0092 - accuracy: 0.9955 - val_loss: 0.0078 - val_accuracy: 0.9957\n",
      "Epoch 17/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9955\n",
      "Epoch 00017: val_loss did not improve from 0.00648\n",
      "3043/3043 [==============================] - 2966s 975ms/step - loss: 0.0091 - accuracy: 0.9955 - val_loss: 0.0076 - val_accuracy: 0.9956\n",
      "Epoch 18/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9956\n",
      "Epoch 00018: val_loss did not improve from 0.00648\n",
      "3043/3043 [==============================] - 2975s 978ms/step - loss: 0.0088 - accuracy: 0.9956 - val_loss: 0.0070 - val_accuracy: 0.9958\n",
      "Epoch 19/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9957\n",
      "Epoch 00019: val_loss did not improve from 0.00648\n",
      "3043/3043 [==============================] - 2966s 975ms/step - loss: 0.0085 - accuracy: 0.9957 - val_loss: 0.0090 - val_accuracy: 0.9953\n",
      "Epoch 20/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9958\n",
      "Epoch 00020: val_loss improved from 0.00648 to 0.00570, saving model to D:PerlmutterData\\model\\model_2019_12_06_17_14.h5\n",
      "3043/3043 [==============================] - 2979s 979ms/step - loss: 0.0081 - accuracy: 0.9958 - val_loss: 0.0057 - val_accuracy: 0.9963\n",
      "Epoch 21/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9958\n",
      "Epoch 00021: val_loss did not improve from 0.00570\n",
      "3043/3043 [==============================] - 2971s 976ms/step - loss: 0.0080 - accuracy: 0.9958 - val_loss: 0.0074 - val_accuracy: 0.9958\n",
      "Epoch 22/500\n",
      "3042/3043 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9958\n",
      "Epoch 00022: val_loss did not improve from 0.00570\n",
      "3043/3043 [==============================] - 2975s 978ms/step - loss: 0.0080 - accuracy: 0.9958 - val_loss: 0.0069 - val_accuracy: 0.9963\n",
      "Epoch 23/500\n",
      "2518/3043 [=======================>......] - ETA: 8:31 - loss: 0.0075 - accuracy: 0.9960"
     ]
    }
   ],
   "source": [
    "# prepare the model\n",
    "unetmodel = UNet(shape = [IMG_HEIGHT, IMG_WIDTH], \n",
    "                 lr = learning_rate, \n",
    "                 loss = loss,\n",
    "                 metrics = metrics,\n",
    "                )\n",
    "\n",
    "# train the model\n",
    "unetmodel.fit_generator(\n",
    "                    generator=train_generator, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=epoch, \n",
    "                    verbose=1, \n",
    "                    # callbacks=[checkpointer], \n",
    "                    callbacks=[checkpointer, tensorboard_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir D:/PerlmetterData/logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "tfdl02",
   "language": "python",
   "name": "tfdl02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
