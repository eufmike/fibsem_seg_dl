{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import itertools\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from core.imageprep import dir_checker, random_crop, crop_generator, random_crop_batch\n",
    "from core.models import UNet\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from core.imageprep import create_crop_idx, crop_to_patch, construct_from_patch\n",
    "from core.train_predict import stack_predict\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "print(\"Load Images...\")\n",
    "# on mac\n",
    "# path = \"/Volumes/LaCie_DataStorage/PerlmutterData/\"\n",
    "\n",
    "# on Window PC \n",
    "path = os.path.join('D:', 'PerlmutterData')\n",
    "\n",
    "# experiment\n",
    "exp_name = 'dl_seg_project_raw'\n",
    "# trianing timestamp\n",
    "imginput_timestamp = '2019_12_06_17_06'\n",
    "model_training_timestamp = '2019_12_06_17_14'\n",
    "print('Training timestamp: {}'.format(model_training_timestamp))\n",
    "\n",
    "# input img path\n",
    "imginput = os.path.join(exp_name, 'data_crop', imginput_timestamp)\n",
    "imgpath = os.path.join(path, imginput)\n",
    "print('Input Images Path: {}'.format(imgpath))\n",
    "\n",
    "# model path\n",
    "modelfd = 'model'\n",
    "modelfn = 'model_' + model_training_timestamp + '.h5'\n",
    "path_model = os.path.join(path, modelfd, modelfn)\n",
    "print('Model Path: {}'.format(path_model))\n",
    "\n",
    "# raw path\n",
    "rawfd = 'raw'\n",
    "path_raw = os.path.join(path, rawfd)\n",
    "print('Raw Path: {}'.format(path_raw))\n",
    "\n",
    "# prediction path\n",
    "pred_path = os.path.join(path, exp_name)\n",
    "dir_checker('pred_img', pred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parameter\n",
    "parsfd = 'pars'\n",
    "parsfn = 'pars_' + model_training_timestamp + '.json'\n",
    "path_pars = os.path.join(path, parsfd, parsfn)\n",
    "\n",
    "with open(path_pars) as json_file:\n",
    "    pars = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pars['inputclass']\n",
    "IMG_HEIGHT = pars['IMG_HEIGHT']\n",
    "IMG_WIDTH = pars['IMG_WIDTH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict from Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "rawfdlist = os.listdir(path_raw)\n",
    "print(rawfdlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawimglist = {}\n",
    "for folder in rawfdlist:\n",
    "    print(folder)\n",
    "    rawimglist[folder] = list(paths.list_images(os.path.join(path_raw, folder, 'Aligned')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(rawimglist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Prediction Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samplesize = 10\n",
    "rawimglist_small = {}\n",
    "for idx, item in rawimglist.items():\n",
    "    rawimglist_small[idx] = rawimglist[idx][:samplesize]\n",
    "pprint(rawimglist_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = imread(rawimglist[rawfdlist[0]][500])\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(path_model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, Conv2DTranspose, Dropout, Flatten, Dense, Activation, Layer, Reshape, Permute, Lambda\n",
    "from tensorflow.keras.layers import Conv3D, MaxPool3D, ZeroPadding3D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "inputs = Input((None, None, 1))\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "print (\"conv1 shape:\",conv1.shape)\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "print (\"conv1 shape:\",conv1.shape)\n",
    "\n",
    "pool1 = MaxPool2D(pool_size=(2, 2))(conv1)\n",
    "print (\"pool1 shape:\",pool1.shape)\n",
    "\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "print (\"conv2 shape:\",conv2.shape)\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "print (\"conv2 shape:\",conv2.shape)\n",
    "pool2 = MaxPool2D(pool_size=(2, 2))(conv2)\n",
    "print (\"pool2 shape:\",pool2.shape)\n",
    "\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "print (\"conv3 shape:\",conv3.shape)\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "print (\"conv3 shape:\",conv3.shape)\n",
    "pool3 = MaxPool2D(pool_size=(2, 2))(conv3)\n",
    "print (\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "pool4 = MaxPool2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = concatenate([drop4,up6])\n",
    "\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = concatenate([conv3, up7])\n",
    "\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = concatenate([conv2, up8])\n",
    "\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = concatenate([conv1, up9])\n",
    "\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\n",
    "output = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "output_shape = Model(inputs , conv9).output_shape\n",
    "\n",
    "newmodel = Model(inputs, output)\n",
    "\n",
    "newmodel.compile(loss=\"binary_crossentropy\", lr=1e-5, metrics=['accuracy'])\n",
    "newmodel.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "newmodel.load_weights(path_model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# folder name\n",
    "fdnm_small = 'batch_01'\n",
    "dir_checker(fdnm_small, os.path.join(pred_path, 'pred_img'))\n",
    "img_path_small = os.path.join(pred_path, 'pred_img', fdnm_small)\n",
    "\n",
    "# create folder list\n",
    "for folder in rawfdlist:\n",
    "    dir_checker(folder, img_path_small)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from core.imageprep import create_crop_idx, crop_to_patch\n",
    "from core.train_predict import stack_predict_v2\n",
    "\n",
    "for idx in trange(len(rawfdlist)):\n",
    "    \n",
    "    folder = rawfdlist[idx]\n",
    "    \n",
    "    pred_input_imgs =  rawimglist_small[folder]\n",
    "    pred_output_path = os.path.join(pred_path, 'pred_img', fdnm_small, folder)\n",
    "    \n",
    "    img = imread(rawimglist_small[folder][0])\n",
    "    # cropidx = create_crop_idx(img.shape, (IMG_HEIGHT, IMG_WIDTH), overlap_fac = 0.1)\n",
    "    # print(cropidx)\n",
    "    \n",
    "    stack_predict_v2(\n",
    "                input_imgpath = pred_input_imgs, \n",
    "                output_imgpath = pred_output_path, \n",
    "                # cropidx = cropidx, \n",
    "                model = newmodel, \n",
    "                rescale = 1./255.,\n",
    "                # patch_size = (IMG_HEIGHT, IMG_WIDTH), \n",
    "                predict_threshold = 0.5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Small Dataset with tiles\n",
    "### Create Folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# folder name\n",
    "fdnm_small = 'batch_01'\n",
    "dir_checker(fdnm_small, os.path.join(pred_path, 'pred_img'))\n",
    "img_path_small = os.path.join(pred_path, 'pred_img', fdnm_small)\n",
    "\n",
    "# create folder list\n",
    "for folder in rawfdlist:\n",
    "    dir_checker(folder, img_path_small)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiling Prediction with Stack Input\n",
    "- Crop image into patched by a given overlap factor\n",
    "- Export a cropping index\n",
    "- Construct patches back into a image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from core.imageprep import create_crop_idx, crop_to_patch\n",
    "\n",
    "for idx in trange(len(rawfdlist)):\n",
    "    \n",
    "    folder = rawfdlist[idx]\n",
    "    \n",
    "    pred_input_imgs =  rawimglist_small[folder]\n",
    "    pred_output_path = os.path.join(pred_path, 'pred_img', fdnm_small, folder)\n",
    "    \n",
    "    img = imread(rawimglist_small[folder][0])\n",
    "    cropidx = create_crop_idx(img.shape, (IMG_HEIGHT, IMG_WIDTH), overlap_fac = 0.1)\n",
    "    # print(cropidx)\n",
    "    \n",
    "    stack_predict(\n",
    "                input_imgpath = pred_input_imgs, \n",
    "                output_imgpath = pred_output_path, \n",
    "                cropidx = cropidx, \n",
    "                model = model, \n",
    "                rescale = 1./255.,\n",
    "                patch_size = (IMG_HEIGHT, IMG_WIDTH), \n",
    "                predict_threshold = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Small Dataset with tiles (whole stack)\n",
    "### Create Folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# folder name\n",
    "fdnm_whole = 'batch_02'\n",
    "dir_checker(fdnm_whole, os.path.join(pred_path, 'pred_img'))\n",
    "img_path_whole = os.path.join(pred_path, 'pred_img', fdnm_whole)\n",
    "\n",
    "# create folder list\n",
    "for folder in rawfdlist:\n",
    "    dir_checker(folder, img_path_whole)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiling Prediction with Stack Input\n",
    "- Crop image into patched by a given overlap factor\n",
    "- Export a cropping index\n",
    "- Construct patches back into a image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from core.imageprep import create_crop_idx, crop_to_patch\n",
    "\n",
    "for idx in trange(len(rawfdlist)):\n",
    "    \n",
    "    folder = rawfdlist[idx]\n",
    "    \n",
    "    pred_input_imgs =  rawimglist[folder]\n",
    "    pred_output_path = os.path.join(pred_path, 'pred_img', fdnm_whole, folder)\n",
    "    \n",
    "    img = imread(rawimglist_small[folder][0])\n",
    "    cropidx = create_crop_idx(img.shape, (IMG_HEIGHT, IMG_WIDTH), overlap_fac = 0.1)\n",
    "    # print(cropidx)\n",
    "    \n",
    "    stack_predict(\n",
    "                input_imgpath = pred_input_imgs, \n",
    "                output_imgpath = pred_output_path, \n",
    "                cropidx = cropidx, \n",
    "                model = model, \n",
    "                rescale = 1./255.,\n",
    "                patch_size = (IMG_HEIGHT, IMG_WIDTH), \n",
    "                predict_threshold = 0.5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdl02",
   "language": "python",
   "name": "tfdl02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
