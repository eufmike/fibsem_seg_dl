{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "1. Keras on Tensorflow\n",
    "2. hyper-parameter search\n",
    "3. vanila-Unet: pull the hyper parameter setting out from the function of model\n",
    "4. date: 01312020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import itertools\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from core.imageprep import dir_checker, random_crop, crop_generator, random_crop_batch\n",
    "from core.models import UNet, UNet_hp, vanilla_unet, vanilla_unet_nodrop\n",
    "from core.metrics import iou_coef, dice_coef\n",
    "\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython import get_ipython\n",
    "# %load_ext autoreload\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "# %autoreload 2\n",
    "get_ipython().run_line_magic('autoreload', '2')\n",
    "# %load_ext tensorboard\n",
    "get_ipython().run_line_magic('load_ext', 'tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wucci_admin\\\\Anaconda3\\\\envs\\\\tfdl02\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Images...\n",
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2020_01_23_09_51_20x\n",
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2020_01_23_09_51_20x\\images\n",
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2020_01_23_09_51_20x\\labels\n",
      "logs exists in D:PerlmutterData\n",
      "fit exists in D:PerlmutterData\\logs\n",
      "model exists in D:PerlmutterData\\logs\n",
      "pars exists in D:PerlmutterData\\logs\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "print(\"Load Images...\")\n",
    "# on mac\n",
    "# path = \"/Volumes/LaCie_DataStorage/PerlmutterData/\"\n",
    "\n",
    "# on Window PC \n",
    "path = os.path.join('D:', 'PerlmutterData')\n",
    "\n",
    "# input set\n",
    "crop_input_set = '2020_01_23_09_51_20x'\n",
    "# crop_input_set = '2020_01_30_11_24_1x' # small training set\n",
    "\n",
    "imginput = os.path.join('dl_seg_project_raw', 'data_crop', crop_input_set,)\n",
    "imgpath = os.path.join(path, imginput)\n",
    "\n",
    "print(imgpath)\n",
    "\n",
    "img_dir = os.path.join(imgpath, 'images')\n",
    "label_dir = os.path.join(imgpath, 'labels')\n",
    "print(img_dir)\n",
    "print(label_dir)\n",
    "\n",
    "# check if the output folder exist. If not, create a folder\n",
    "dir_checker('logs', path)\n",
    "path_logs = os.path.join(path, 'logs')\n",
    "dir_checker('fit', path_logs)\n",
    "dir_checker('model', path_logs)\n",
    "dir_checker('pars', path_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Print the first file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:PerlmutterData\\dl_seg_project_raw\\data_crop\\2020_01_23_09_51_20x\\images\\nucleus\\0001.tif\n"
     ]
    }
   ],
   "source": [
    "imgpath_all = list(paths.list_images(imgpath))\n",
    "print(imgpath_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Create Image Datagenerator\n",
    " 1. create only one datagen\n",
    " 2. specify valiation split in datagen argument\n",
    " 3. add split data when calling `datagen.flow_from_directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "date =  datetime.now().strftime(\"%Y_%m_%d\")\n",
    "seed = 102\n",
    "batch_size = 16\n",
    "epoch = 20\n",
    "validation_steps = 20\n",
    "validation_split = 0.3\n",
    "training_sample_size = len(imgpath_all)\n",
    "IMG_HEIGHT = None\n",
    "IMG_WIDTH = None\n",
    "classes = ['cell_membrane', 'nucleus', 'autophagosome']\n",
    "inputclass = [classes[1]]\n",
    "learning_rate = 1e-4\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = ['accuracy', iou_coef, dice_coef]\n",
    "\n",
    "metrics_name = []\n",
    "for f in metrics:\n",
    "    if callable(f):\n",
    "        metrics_name.append(f.__name__)\n",
    "    else:\n",
    "        metrics_name.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nucleus exists in D:PerlmutterData\\logs\\pars\n",
      "2020_02_03 exists in D:PerlmutterData\\logs\\pars\\nucleus\n",
      "{'IMG_HEIGHT': None,\n",
      " 'IMG_WIDTH': None,\n",
      " 'batch_size': 16,\n",
      " 'classes': ['cell_membrane', 'nucleus', 'autophagosome'],\n",
      " 'crop_input_set': '2020_01_23_09_51_20x',\n",
      " 'data_gen_img_args': {'height_shift_range': 0.1,\n",
      "                       'horizontal_flip': True,\n",
      "                       'rescale': 0.00392156862745098,\n",
      "                       'rotation_range': 90.0,\n",
      "                       'shear_range': 0.07,\n",
      "                       'validation_split': 0.3,\n",
      "                       'vertical_flip': True,\n",
      "                       'width_shift_range': 0.1,\n",
      "                       'zoom_range': 0.2},\n",
      " 'data_gen_label_args': {'height_shift_range': 0.1,\n",
      "                         'horizontal_flip': True,\n",
      "                         'rescale': 0.00392156862745098,\n",
      "                         'rotation_range': 90.0,\n",
      "                         'shear_range': 0.07,\n",
      "                         'validation_split': 0.3,\n",
      "                         'vertical_flip': True,\n",
      "                         'width_shift_range': 0.1,\n",
      "                         'zoom_range': 0.2},\n",
      " 'date': '2020_02_03',\n",
      " 'epoch': 20,\n",
      " 'inputclass': ['nucleus'],\n",
      " 'learning_rate': 0.0001,\n",
      " 'loss': 'binary_crossentropy',\n",
      " 'metrics_name': ['accuracy', 'iou_coef', 'dice_coef'],\n",
      " 'seed': 102,\n",
      " 'timestamp': '2020_02_03_09_07',\n",
      " 'training_sample_size': 13240,\n",
      " 'validation_split': 0.3,\n",
      " 'validation_steps': 20}\n"
     ]
    }
   ],
   "source": [
    "# create arguments for data generator\n",
    "data_gen_img_args = dict(\n",
    "                # featurewise_center = True,\n",
    "                # featurewise_std_normalization = True,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True,\n",
    "                rotation_range = 90.,\n",
    "                width_shift_range = 0.1,\n",
    "                height_shift_range = 0.1,\n",
    "                shear_range = 0.07,\n",
    "                zoom_range = 0.2,\n",
    "                validation_split = validation_split, # <- specify validation_split ratio\n",
    "                # fill_mode='constant',\n",
    "                # cval=0.,\n",
    "                rescale=1.0/255.0,\n",
    "                )\n",
    "\n",
    "data_gen_label_args = dict(\n",
    "                # featurewise_center=True,\n",
    "                # featurewise_std_normalization=True,\n",
    "                horizontal_flip = True,\n",
    "                vertical_flip = True,\n",
    "                rotation_range = 90.,\n",
    "                width_shift_range = 0.1,\n",
    "                height_shift_range = 0.1,\n",
    "                shear_range = 0.07,\n",
    "                zoom_range = 0.2,\n",
    "                validation_split = validation_split, # <- specify validation_split ratio\n",
    "                # fill_mode='constant',\n",
    "                # cval=0.,\n",
    "                # rescale=1.0/255.0,\n",
    "                rescale=1.0/255.0,\n",
    "                )\n",
    "\n",
    "# create parameter\n",
    "pars = dict(\n",
    "                # basic information\n",
    "                timestamp = timestamp,\n",
    "                date = date,\n",
    "                seed = seed,\n",
    "                batch_size = batch_size,\n",
    "                \n",
    "                # Data generator\n",
    "                crop_input_set = crop_input_set,\n",
    "                validation_steps = validation_steps,\n",
    "                validation_split = validation_split,\n",
    "                training_sample_size = training_sample_size,\n",
    "                \n",
    "                # training class\n",
    "                classes = classes,\n",
    "                inputclass = inputclass,\n",
    "    \n",
    "                # add datagen args\n",
    "                data_gen_img_args = data_gen_img_args,\n",
    "                data_gen_label_args = data_gen_label_args,\n",
    "                \n",
    "                # Build model\n",
    "                IMG_HEIGHT = IMG_HEIGHT,\n",
    "                IMG_WIDTH = IMG_WIDTH,\n",
    "                epoch = epoch, \n",
    "                loss = loss,\n",
    "                metrics_name = metrics_name,\n",
    "                learning_rate = learning_rate,\n",
    "                )\n",
    "\n",
    "# save parameter\n",
    "path_pars = os.path.join(path_logs, 'pars')\n",
    "dir_checker(inputclass[0], path_pars)\n",
    "dir_checker(date, os.path.join(path_pars, inputclass[0]))\n",
    "\n",
    "pprint(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:PerlmutterData\\logs\\pars\\nucleus\\2020_02_03\\pars_2020_02_03_09_07.json\n"
     ]
    }
   ],
   "source": [
    "par_file_dir = os.path.join(path_pars, inputclass[0], date, 'pars_' + timestamp + '.json')\n",
    "print(par_file_dir)\n",
    "\n",
    "with open(par_file_dir, 'w') as outfile:\n",
    "    json.dump(pars, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator\n",
    "image_datagen = ImageDataGenerator(**data_gen_img_args)\n",
    "label_datagen = ImageDataGenerator(**data_gen_label_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4634 images belonging to 1 classes.\n",
      "Found 4634 images belonging to 1 classes.\n",
      "Found 1986 images belonging to 1 classes.\n",
      "Found 1986 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# load images into generator\n",
    "train_image_generator = image_datagen.flow_from_directory(\n",
    "    img_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='training', # <- define subset as 'training'\n",
    "    seed=seed)\n",
    "\n",
    "train_label_generator = label_datagen.flow_from_directory(\n",
    "    label_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "valid_image_generator = image_datagen.flow_from_directory(\n",
    "    img_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation', # <- define subset as 'validation'\n",
    "    seed=seed)\n",
    "\n",
    "valid_label_generator = label_datagen.flow_from_directory(\n",
    "    label_dir,\n",
    "    class_mode=None,\n",
    "    classes=inputclass,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge image and label generator\n",
    "def combine_generator(gen1, gen2):\n",
    "    while True:\n",
    "        yield(gen1.next(), gen2.next()) \n",
    "train_generator = combine_generator(train_image_generator, train_label_generator)\n",
    "valid_generator = combine_generator(valid_image_generator, valid_label_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_generator = zip(train_image_generator, train_label_generator)\\nvalid_generator = zip(valid_image_generator, valid_label_generator)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_generator = zip(train_image_generator, train_label_generator)\n",
    "valid_generator = zip(valid_image_generator, valid_label_generator)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 579.0\n"
     ]
    }
   ],
   "source": [
    "# calculate steps_per_epoch\n",
    "steps_per_epoch = training_sample_size * (1 - validation_split) // batch_size\n",
    "print(\"Steps per epoch: {}\".format(steps_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "# Create a .v2 file for saving hyperparameter and evaluation\n",
    "# so we can see the results on tensorboard\n",
    "hparamtuning_dir = os.path.join(path_logs, 'fit', inputclass[0], date, timestamp)\n",
    "\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.5, 0.7]))\n",
    "HP_LAYERS = hp.HParam('layers', hp.Discrete([5, 4]))\n",
    "\n",
    "# hparams_list = [HP_DROPOUT, HP_LAYERS]\n",
    "\n",
    "with tf.summary.create_file_writer(hparamtuning_dir).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_DROPOUT, HP_LAYERS],\n",
    "        metrics=[hp.Metric('accuracy', display_name='Accuracy'), \n",
    "                 hp.Metric('iou_coef', display_name='IoU_Coef'), # create container for customized metrics\n",
    "                 hp.Metric('dice_coef', display_name='Dice_Coef')], # the same\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_name, hparamtuning_dir, hparams):\n",
    "    \n",
    "    # checkpoint\n",
    "    modelfilename = 'model_' + timestamp + '.h5'\n",
    "    dir_checker(run_name, hparamtuning_dir)\n",
    "    dir_checker('model', os.path.join(hparamtuning_dir, run_name))\n",
    "    \n",
    "    modelfile_path = os.path.join(hparamtuning_dir, run_name, 'model', modelfilename)\n",
    "    checkpointer = ModelCheckpoint(filepath = modelfile_path, \n",
    "                                   monitor = 'val_loss', \n",
    "                                   mode = 'min', \n",
    "                                   verbose = 1, \n",
    "                                   save_best_only = True)\n",
    "\n",
    "    # early stopping \n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=8,\n",
    "                               verbose=1,\n",
    "                               min_delta=1e-4)\n",
    "\n",
    "    # learning rate adjustment\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss',\n",
    "                        factor=0.1,\n",
    "                        patience=4,\n",
    "                        verbose=1,\n",
    "                        min_delta=1e-4)\n",
    "\n",
    "    # tensorboard ----------------------------------------------\n",
    "    \n",
    "    # file_writer = create_file_writer(os.path.join(path_logs, 'fit', inputclass[0], date, timestamp, \"metrics\"))\n",
    "    # file_writer.set_as_default()\n",
    "\n",
    "    metrics = ['accuracy', iou_coef, dice_coef]\n",
    "    \n",
    "    tensorboard_callback = TensorBoard(log_dir = os.path.join(hparamtuning_dir, run_name), \n",
    "                                       profile_batch = 0, \n",
    "                                       update_freq= 30,\n",
    "                                       histogram_freq = 1\n",
    "                                       )\n",
    "\n",
    "    # compile callbacks\n",
    "    # callbacks = [checkpointer, tensorboard_callback, early_stopping, reduceLR]\n",
    "    callbacks = [checkpointer, reduceLR, tensorboard_callback]\n",
    "    \n",
    "    hparamtuning_runname_dir = os.path.join(hparamtuning_dir, run_name)\n",
    "    \n",
    "    \n",
    "    with tf.summary.create_file_writer(hparamtuning_runname_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "\n",
    "        # prepare the model -----------------------------------\n",
    "        \n",
    "        # load hyper-parameter\n",
    "        dropout = float(hparams[HP_DROPOUT])\n",
    "        print('dropout: {}'.format(dropout))\n",
    "        \n",
    "        num_layers = int(hparams[HP_LAYERS])\n",
    "        print('num layers: {}'.format(num_layers))\n",
    "        \n",
    "        unetmodel = vanilla_unet_nodrop(\n",
    "                            shape = (IMG_HEIGHT, IMG_WIDTH), \n",
    "                            dropout = dropout, \n",
    "                            num_layers = num_layers, \n",
    "                            lr = learning_rate, \n",
    "                            loss = loss,\n",
    "                            metrics = metrics,\n",
    "                            summary = False,\n",
    "                           )\n",
    "        \n",
    "        # load model ------------------------------------------\n",
    "        \n",
    "        '''\n",
    "        # load weight\n",
    "        path_model = os.path.join('D:', 'PerlmutterData', 'logs', 'model', \n",
    "                                'nucleus', \n",
    "                                '2019_12_13',\n",
    "                                '2019_12_13_17_28',\n",
    "                                'run-1', \n",
    "                                'model_2019_12_13_17_28.h5',)\n",
    "        \n",
    "        unetmodel.load_weights(path_model)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # train the model -------------------------------------\n",
    "        unetmodel.fit_generator(\n",
    "                            generator = train_generator, \n",
    "                            validation_data = valid_generator,\n",
    "                            validation_steps = validation_steps,\n",
    "                            steps_per_epoch = steps_per_epoch,\n",
    "                            epochs = epoch,  \n",
    "                            callbacks = callbacks,\n",
    "                            verbose = 1, \n",
    "                            )\n",
    "    \n",
    "        _, accuracy, iou, dice,  = unetmodel.evaluate_generator(valid_generator, steps = 50, verbose=1)\n",
    "        tf.summary.scalar('accuracy', accuracy, step = 1)\n",
    "        tf.summary.scalar('iou_coef', iou, step = 1)\n",
    "        tf.summary.scalar('dice_coef', dice, step = 1)\n",
    "        \n",
    "        # -----------------------------------------------------\n",
    "        \n",
    "        # clean memory\n",
    "        K.clear_session()\n",
    "        del unetmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{HParam(name='dropout', domain=Discrete([0.5, 0.7]), display_name=None, description=None): 0.5, HParam(name='layers', domain=Discrete([4, 5]), display_name=None, description=None): 4}\n",
      "{'dropout': 0.5, 'layers': 4}\n",
      "run-0 exists in D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\n",
      "model exists in D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\n",
      "dropout: 0.5\n",
      "num layers: 4\n",
      "Epoch 1/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.5970 - accuracy: 0.7226 - iou_coef: 0.0935 - dice_coef: 0.1484\n",
      "Epoch 00001: val_loss improved from inf to 0.79721, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 513s 886ms/step - loss: 0.5970 - accuracy: 0.7227 - iou_coef: 0.0935 - dice_coef: 0.1483 - val_loss: 0.7972 - val_accuracy: 0.5432 - val_iou_coef: 0.1258 - val_dice_coef: 0.2055\n",
      "Epoch 2/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.5673 - accuracy: 0.7237 - iou_coef: 0.0996 - dice_coef: 0.1557\n",
      "Epoch 00002: val_loss did not improve from 0.79721\n",
      "579/579 [==============================] - 502s 867ms/step - loss: 0.5677 - accuracy: 0.7234 - iou_coef: 0.0997 - dice_coef: 0.1558 - val_loss: 0.8259 - val_accuracy: 0.5906 - val_iou_coef: 0.1321 - val_dice_coef: 0.2080\n",
      "Epoch 3/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.7264 - iou_coef: 0.1110 - dice_coef: 0.1683\n",
      "Epoch 00003: val_loss improved from 0.79721 to 0.69592, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 504s 870ms/step - loss: 0.5254 - accuracy: 0.7263 - iou_coef: 0.1110 - dice_coef: 0.1684 - val_loss: 0.6959 - val_accuracy: 0.5610 - val_iou_coef: 0.1692 - val_dice_coef: 0.2558\n",
      "Epoch 4/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.5129 - accuracy: 0.7253 - iou_coef: 0.1159 - dice_coef: 0.1737\n",
      "Epoch 00004: val_loss did not improve from 0.69592\n",
      "579/579 [==============================] - 502s 866ms/step - loss: 0.5129 - accuracy: 0.7252 - iou_coef: 0.1161 - dice_coef: 0.1739 - val_loss: 0.7633 - val_accuracy: 0.5693 - val_iou_coef: 0.1969 - val_dice_coef: 0.2676\n",
      "Epoch 5/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.4398 - accuracy: 0.7884 - iou_coef: 0.1556 - dice_coef: 0.2089\n",
      "Epoch 00005: val_loss did not improve from 0.69592\n",
      "579/579 [==============================] - 501s 866ms/step - loss: 0.4399 - accuracy: 0.7882 - iou_coef: 0.1555 - dice_coef: 0.2088 - val_loss: 0.7117 - val_accuracy: 0.5357 - val_iou_coef: 0.1862 - val_dice_coef: 0.2756\n",
      "Epoch 6/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.4491 - accuracy: 0.7925 - iou_coef: 0.1531 - dice_coef: 0.2051\n",
      "Epoch 00006: val_loss improved from 0.69592 to 0.64368, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 501s 866ms/step - loss: 0.4489 - accuracy: 0.7927 - iou_coef: 0.1531 - dice_coef: 0.2051 - val_loss: 0.6437 - val_accuracy: 0.7231 - val_iou_coef: 0.1936 - val_dice_coef: 0.2707\n",
      "Epoch 7/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9347 - iou_coef: 0.2714 - dice_coef: 0.3048\n",
      "Epoch 00007: val_loss improved from 0.64368 to 0.40314, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 497s 858ms/step - loss: 0.2050 - accuracy: 0.9348 - iou_coef: 0.2713 - dice_coef: 0.3048 - val_loss: 0.4031 - val_accuracy: 0.8732 - val_iou_coef: 0.3305 - val_dice_coef: 0.3839\n",
      "Epoch 8/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1814 - accuracy: 0.9443 - iou_coef: 0.2851 - dice_coef: 0.3157\n",
      "Epoch 00008: val_loss improved from 0.40314 to 0.34263, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 496s 856ms/step - loss: 0.1818 - accuracy: 0.9442 - iou_coef: 0.2851 - dice_coef: 0.3156 - val_loss: 0.3426 - val_accuracy: 0.9017 - val_iou_coef: 0.4264 - val_dice_coef: 0.4570\n",
      "Epoch 9/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9474 - iou_coef: 0.2899 - dice_coef: 0.3190\n",
      "Epoch 00009: val_loss improved from 0.34263 to 0.29890, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 496s 857ms/step - loss: 0.1745 - accuracy: 0.9475 - iou_coef: 0.2902 - dice_coef: 0.3192 - val_loss: 0.2989 - val_accuracy: 0.9178 - val_iou_coef: 0.4209 - val_dice_coef: 0.4582\n",
      "Epoch 10/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.2883 - accuracy: 0.8809 - iou_coef: 0.2336 - dice_coef: 0.2732\n",
      "Epoch 00010: val_loss did not improve from 0.29890\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 0.2880 - accuracy: 0.8811 - iou_coef: 0.2340 - dice_coef: 0.2736 - val_loss: 0.3194 - val_accuracy: 0.9176 - val_iou_coef: 0.3457 - val_dice_coef: 0.3893\n",
      "Epoch 11/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9508 - iou_coef: 0.2973 - dice_coef: 0.3259\n",
      "Epoch 00011: val_loss improved from 0.29890 to 0.22992, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 496s 857ms/step - loss: 0.1704 - accuracy: 0.9508 - iou_coef: 0.2973 - dice_coef: 0.3259 - val_loss: 0.2299 - val_accuracy: 0.9348 - val_iou_coef: 0.4184 - val_dice_coef: 0.4568\n",
      "Epoch 12/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9519 - iou_coef: 0.3017 - dice_coef: 0.3298\n",
      "Epoch 00012: val_loss did not improve from 0.22992\n",
      "579/579 [==============================] - 495s 854ms/step - loss: 0.1671 - accuracy: 0.9518 - iou_coef: 0.3015 - dice_coef: 0.3295 - val_loss: 0.3069 - val_accuracy: 0.9178 - val_iou_coef: 0.4706 - val_dice_coef: 0.5144\n",
      "Epoch 13/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1625 - accuracy: 0.9531 - iou_coef: 0.3056 - dice_coef: 0.3328\n",
      "Epoch 00013: val_loss did not improve from 0.22992\n",
      "579/579 [==============================] - 495s 854ms/step - loss: 0.1625 - accuracy: 0.9531 - iou_coef: 0.3057 - dice_coef: 0.3329 - val_loss: 0.2614 - val_accuracy: 0.9299 - val_iou_coef: 0.4533 - val_dice_coef: 0.4863\n",
      "Epoch 14/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9526 - iou_coef: 0.3057 - dice_coef: 0.3329\n",
      "Epoch 00014: val_loss did not improve from 0.22992\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 0.1640 - accuracy: 0.9523 - iou_coef: 0.3055 - dice_coef: 0.3328 - val_loss: 0.3512 - val_accuracy: 0.8865 - val_iou_coef: 0.3502 - val_dice_coef: 0.4086\n",
      "Epoch 15/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9541 - iou_coef: 0.3031 - dice_coef: 0.3303\n",
      "Epoch 00015: val_loss did not improve from 0.22992\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 0.1593 - accuracy: 0.9542 - iou_coef: 0.3032 - dice_coef: 0.3305 - val_loss: 0.2814 - val_accuracy: 0.9208 - val_iou_coef: 0.4559 - val_dice_coef: 0.4948\n",
      "Epoch 16/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9575 - iou_coef: 0.3152 - dice_coef: 0.3399\n",
      "Epoch 00016: val_loss did not improve from 0.22992\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 0.1472 - accuracy: 0.9574 - iou_coef: 0.3153 - dice_coef: 0.3400 - val_loss: 0.2519 - val_accuracy: 0.9317 - val_iou_coef: 0.3998 - val_dice_coef: 0.4335\n",
      "Epoch 17/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9585 - iou_coef: 0.3194 - dice_coef: 0.3440\n",
      "Epoch 00017: val_loss improved from 0.22992 to 0.20818, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 495s 855ms/step - loss: 0.1398 - accuracy: 0.9585 - iou_coef: 0.3195 - dice_coef: 0.3441 - val_loss: 0.2082 - val_accuracy: 0.9326 - val_iou_coef: 0.4127 - val_dice_coef: 0.4479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9581 - iou_coef: 0.3172 - dice_coef: 0.3415\n",
      "Epoch 00018: val_loss did not improve from 0.20818\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 0.1385 - accuracy: 0.9580 - iou_coef: 0.3172 - dice_coef: 0.3415 - val_loss: 0.2151 - val_accuracy: 0.9371 - val_iou_coef: 0.4279 - val_dice_coef: 0.4713\n",
      "Epoch 19/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1331 - accuracy: 0.9585 - iou_coef: 0.3228 - dice_coef: 0.3470\n",
      "Epoch 00019: val_loss improved from 0.20818 to 0.20463, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 496s 856ms/step - loss: 0.1330 - accuracy: 0.9586 - iou_coef: 0.3230 - dice_coef: 0.3472 - val_loss: 0.2046 - val_accuracy: 0.9348 - val_iou_coef: 0.4580 - val_dice_coef: 0.5027\n",
      "Epoch 20/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.9593 - iou_coef: 0.3221 - dice_coef: 0.3456\n",
      "Epoch 00020: val_loss improved from 0.20463 to 0.18428, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-0\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 496s 857ms/step - loss: 0.1286 - accuracy: 0.9594 - iou_coef: 0.3224 - dice_coef: 0.3459 - val_loss: 0.1843 - val_accuracy: 0.9439 - val_iou_coef: 0.4529 - val_dice_coef: 0.4964\n",
      "50/50 [==============================] - 16s 311ms/step - loss: 0.2072 - accuracy: 0.9390 - iou_coef: 0.4527 - dice_coef: 0.4966\n",
      "--- Starting trial: run-1\n",
      "{HParam(name='dropout', domain=Discrete([0.5, 0.7]), display_name=None, description=None): 0.5, HParam(name='layers', domain=Discrete([4, 5]), display_name=None, description=None): 5}\n",
      "{'dropout': 0.5, 'layers': 5}\n",
      "run-1 does not exist in D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\n",
      "model does not exist in D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-1\n",
      "dropout: 0.5\n",
      "num layers: 5\n",
      "Epoch 1/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.5994 - accuracy: 0.7221 - iou_coef: 0.0938 - dice_coef: 0.1490\n",
      "Epoch 00001: val_loss improved from inf to 0.74411, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-1\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 656s 1s/step - loss: 0.5993 - accuracy: 0.7222 - iou_coef: 0.0937 - dice_coef: 0.1490 - val_loss: 0.7441 - val_accuracy: 0.5675 - val_iou_coef: 0.1291 - val_dice_coef: 0.2084\n",
      "Epoch 2/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.5485 - accuracy: 0.7251 - iou_coef: 0.1033 - dice_coef: 0.1599\n",
      "Epoch 00002: val_loss did not improve from 0.74411\n",
      "579/579 [==============================] - 652s 1s/step - loss: 0.5485 - accuracy: 0.7250 - iou_coef: 0.1033 - dice_coef: 0.1599 - val_loss: 0.8679 - val_accuracy: 0.5370 - val_iou_coef: 0.1463 - val_dice_coef: 0.2255\n",
      "Epoch 3/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.5189 - accuracy: 0.7292 - iou_coef: 0.1141 - dice_coef: 0.1706\n",
      "Epoch 00003: val_loss improved from 0.74411 to 0.66998, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-1\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 656s 1s/step - loss: 0.5190 - accuracy: 0.7291 - iou_coef: 0.1141 - dice_coef: 0.1706 - val_loss: 0.6700 - val_accuracy: 0.6154 - val_iou_coef: 0.1362 - val_dice_coef: 0.2093\n",
      "Epoch 4/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.5106 - accuracy: 0.7361 - iou_coef: 0.1164 - dice_coef: 0.1725\n",
      "Epoch 00004: val_loss did not improve from 0.66998\n",
      "579/579 [==============================] - 651s 1s/step - loss: 0.5105 - accuracy: 0.7361 - iou_coef: 0.1164 - dice_coef: 0.1726 - val_loss: 0.7410 - val_accuracy: 0.6216 - val_iou_coef: 0.1694 - val_dice_coef: 0.2502\n",
      "Epoch 5/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.5007 - accuracy: 0.7413 - iou_coef: 0.1236 - dice_coef: 0.1799\n",
      "Epoch 00005: val_loss did not improve from 0.66998\n",
      "579/579 [==============================] - 650s 1s/step - loss: 0.5006 - accuracy: 0.7413 - iou_coef: 0.1235 - dice_coef: 0.1799 - val_loss: 0.9222 - val_accuracy: 0.5649 - val_iou_coef: 0.0844 - val_dice_coef: 0.1445\n",
      "Epoch 6/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.3132 - accuracy: 0.8849 - iou_coef: 0.2178 - dice_coef: 0.2591\n",
      "Epoch 00006: val_loss did not improve from 0.66998\n",
      "579/579 [==============================] - 649s 1s/step - loss: 0.3134 - accuracy: 0.8848 - iou_coef: 0.2175 - dice_coef: 0.2589 - val_loss: 0.9925 - val_accuracy: 0.5086 - val_iou_coef: 0.1132 - val_dice_coef: 0.1868\n",
      "Epoch 7/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.3553 - accuracy: 0.8474 - iou_coef: 0.1915 - dice_coef: 0.2368\n",
      "Epoch 00007: val_loss improved from 0.66998 to 0.38615, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-1\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 654s 1s/step - loss: 0.3549 - accuracy: 0.8476 - iou_coef: 0.1918 - dice_coef: 0.2370 - val_loss: 0.3862 - val_accuracy: 0.8920 - val_iou_coef: 0.3453 - val_dice_coef: 0.3781\n",
      "Epoch 8/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.2796 - accuracy: 0.8929 - iou_coef: 0.2318 - dice_coef: 0.2687\n",
      "Epoch 00008: val_loss improved from 0.38615 to 0.20262, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-1\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 653s 1s/step - loss: 0.2793 - accuracy: 0.8931 - iou_coef: 0.2320 - dice_coef: 0.2689 - val_loss: 0.2026 - val_accuracy: 0.9391 - val_iou_coef: 0.4409 - val_dice_coef: 0.4859\n",
      "Epoch 9/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1690 - accuracy: 0.9502 - iou_coef: 0.2923 - dice_coef: 0.3192\n",
      "Epoch 00009: val_loss improved from 0.20262 to 0.17351, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-1\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 654s 1s/step - loss: 0.1690 - accuracy: 0.9501 - iou_coef: 0.2924 - dice_coef: 0.3194 - val_loss: 0.1735 - val_accuracy: 0.9437 - val_iou_coef: 0.4454 - val_dice_coef: 0.4753\n",
      "Epoch 10/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1809 - accuracy: 0.9469 - iou_coef: 0.2885 - dice_coef: 0.3153\n",
      "Epoch 00010: val_loss did not improve from 0.17351\n",
      "579/579 [==============================] - 649s 1s/step - loss: 0.1808 - accuracy: 0.9470 - iou_coef: 0.2886 - dice_coef: 0.3155 - val_loss: 0.3589 - val_accuracy: 0.9063 - val_iou_coef: 0.3530 - val_dice_coef: 0.3963\n",
      "Epoch 11/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1682 - accuracy: 0.9521 - iou_coef: 0.2979 - dice_coef: 0.3243\n",
      "Epoch 00011: val_loss improved from 0.17351 to 0.16705, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-1\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 653s 1s/step - loss: 0.1681 - accuracy: 0.9521 - iou_coef: 0.2975 - dice_coef: 0.3239 - val_loss: 0.1671 - val_accuracy: 0.9386 - val_iou_coef: 0.4218 - val_dice_coef: 0.4650\n",
      "Epoch 12/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1589 - accuracy: 0.9544 - iou_coef: 0.3025 - dice_coef: 0.3280\n",
      "Epoch 00012: val_loss did not improve from 0.16705\n",
      "579/579 [==============================] - 649s 1s/step - loss: 0.1588 - accuracy: 0.9544 - iou_coef: 0.3028 - dice_coef: 0.3284 - val_loss: 0.2883 - val_accuracy: 0.9330 - val_iou_coef: 0.4351 - val_dice_coef: 0.4622\n",
      "Epoch 13/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1562 - accuracy: 0.9548 - iou_coef: 0.3082 - dice_coef: 0.3331\n",
      "Epoch 00013: val_loss improved from 0.16705 to 0.13314, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-1\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 654s 1s/step - loss: 0.1560 - accuracy: 0.9548 - iou_coef: 0.3081 - dice_coef: 0.3331 - val_loss: 0.1331 - val_accuracy: 0.9549 - val_iou_coef: 0.4862 - val_dice_coef: 0.5157\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/579 [============================>.] - ETA: 1s - loss: 0.1492 - accuracy: 0.9569 - iou_coef: 0.3091 - dice_coef: 0.3339\n",
      "Epoch 00014: val_loss did not improve from 0.13314\n",
      "579/579 [==============================] - 649s 1s/step - loss: 0.1495 - accuracy: 0.9569 - iou_coef: 0.3092 - dice_coef: 0.3340 - val_loss: 0.2591 - val_accuracy: 0.9340 - val_iou_coef: 0.4376 - val_dice_coef: 0.4712\n",
      "Epoch 15/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1597 - accuracy: 0.9541 - iou_coef: 0.3094 - dice_coef: 0.3353\n",
      "Epoch 00015: val_loss did not improve from 0.13314\n",
      "579/579 [==============================] - 650s 1s/step - loss: 0.1598 - accuracy: 0.9541 - iou_coef: 0.3092 - dice_coef: 0.3350 - val_loss: 0.1395 - val_accuracy: 0.9598 - val_iou_coef: 0.4813 - val_dice_coef: 0.5151\n",
      "Epoch 16/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1467 - accuracy: 0.9574 - iou_coef: 0.3127 - dice_coef: 0.3373\n",
      "Epoch 00016: val_loss did not improve from 0.13314\n",
      "579/579 [==============================] - 650s 1s/step - loss: 0.1469 - accuracy: 0.9574 - iou_coef: 0.3126 - dice_coef: 0.3372 - val_loss: 0.3021 - val_accuracy: 0.9092 - val_iou_coef: 0.4417 - val_dice_coef: 0.4765\n",
      "Epoch 17/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1451 - accuracy: 0.9566 - iou_coef: 0.3167 - dice_coef: 0.3412\n",
      "Epoch 00017: val_loss did not improve from 0.13314\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "579/579 [==============================] - 649s 1s/step - loss: 0.1449 - accuracy: 0.9567 - iou_coef: 0.3164 - dice_coef: 0.3409 - val_loss: 0.3106 - val_accuracy: 0.9109 - val_iou_coef: 0.4195 - val_dice_coef: 0.4520\n",
      "Epoch 18/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1148 - accuracy: 0.9641 - iou_coef: 0.3271 - dice_coef: 0.3475\n",
      "Epoch 00018: val_loss did not improve from 0.13314\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1147 - accuracy: 0.9641 - iou_coef: 0.3272 - dice_coef: 0.3476 - val_loss: 0.3066 - val_accuracy: 0.8972 - val_iou_coef: 0.4181 - val_dice_coef: 0.4571\n",
      "Epoch 19/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1002 - accuracy: 0.9666 - iou_coef: 0.3330 - dice_coef: 0.3522\n",
      "Epoch 00019: val_loss did not improve from 0.13314\n",
      "579/579 [==============================] - 648s 1s/step - loss: 0.1002 - accuracy: 0.9666 - iou_coef: 0.3330 - dice_coef: 0.3522 - val_loss: 0.3179 - val_accuracy: 0.8811 - val_iou_coef: 0.3882 - val_dice_coef: 0.4267\n",
      "Epoch 20/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.0891 - accuracy: 0.9698 - iou_coef: 0.3383 - dice_coef: 0.3561\n",
      "Epoch 00020: val_loss did not improve from 0.13314\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.0890 - accuracy: 0.9698 - iou_coef: 0.3383 - dice_coef: 0.3561 - val_loss: 0.2338 - val_accuracy: 0.9128 - val_iou_coef: 0.4235 - val_dice_coef: 0.4580\n",
      "50/50 [==============================] - 19s 374ms/step - loss: 0.3547 - accuracy: 0.8739 - iou_coef: 0.3928 - dice_coef: 0.4316\n",
      "--- Starting trial: run-2\n",
      "{HParam(name='dropout', domain=Discrete([0.5, 0.7]), display_name=None, description=None): 0.7, HParam(name='layers', domain=Discrete([4, 5]), display_name=None, description=None): 4}\n",
      "{'dropout': 0.7, 'layers': 4}\n",
      "run-2 does not exist in D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\n",
      "model does not exist in D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-2\n",
      "dropout: 0.7\n",
      "num layers: 4\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "  1/579 [..............................] - ETA: 12:11 - loss: 1.1364 - accuracy: 0.2452 - iou_coef: 0.1644 - dice_coef: 0.2243WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.5638 - accuracy: 0.7213 - iou_coef: 0.1027 - dice_coef: 0.1590\n",
      "Epoch 00001: val_loss improved from inf to 0.76110, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-2\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 499s 862ms/step - loss: 0.5637 - accuracy: 0.7214 - iou_coef: 0.1027 - dice_coef: 0.1590 - val_loss: 0.7611 - val_accuracy: 0.5500 - val_iou_coef: 0.1469 - val_dice_coef: 0.2315\n",
      "Epoch 2/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.5288 - accuracy: 0.7246 - iou_coef: 0.1132 - dice_coef: 0.1709\n",
      "Epoch 00002: val_loss improved from 0.76110 to 0.70833, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-2\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 497s 858ms/step - loss: 0.5288 - accuracy: 0.7245 - iou_coef: 0.1132 - dice_coef: 0.1709 - val_loss: 0.7083 - val_accuracy: 0.5764 - val_iou_coef: 0.1611 - val_dice_coef: 0.2454\n",
      "Epoch 3/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.5149 - accuracy: 0.7384 - iou_coef: 0.1188 - dice_coef: 0.1755\n",
      "Epoch 00003: val_loss did not improve from 0.70833\n",
      "579/579 [==============================] - 495s 854ms/step - loss: 0.5149 - accuracy: 0.7384 - iou_coef: 0.1188 - dice_coef: 0.1755 - val_loss: 0.7329 - val_accuracy: 0.5449 - val_iou_coef: 0.1539 - val_dice_coef: 0.2390\n",
      "Epoch 4/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8262 - iou_coef: 0.1792 - dice_coef: 0.2303\n",
      "Epoch 00004: val_loss improved from 0.70833 to 0.38794, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-2\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 498s 861ms/step - loss: 0.3848 - accuracy: 0.8263 - iou_coef: 0.1792 - dice_coef: 0.2304 - val_loss: 0.3879 - val_accuracy: 0.8470 - val_iou_coef: 0.3230 - val_dice_coef: 0.3892\n",
      "Epoch 5/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9196 - iou_coef: 0.2544 - dice_coef: 0.2923\n",
      "Epoch 00005: val_loss improved from 0.38794 to 0.22525, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-2\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 498s 860ms/step - loss: 0.2350 - accuracy: 0.9195 - iou_coef: 0.2546 - dice_coef: 0.2925 - val_loss: 0.2253 - val_accuracy: 0.9096 - val_iou_coef: 0.3928 - val_dice_coef: 0.4526\n",
      "Epoch 6/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.2027 - accuracy: 0.9351 - iou_coef: 0.2740 - dice_coef: 0.3073\n",
      "Epoch 00006: val_loss did not improve from 0.22525\n",
      "579/579 [==============================] - 496s 857ms/step - loss: 0.2027 - accuracy: 0.9351 - iou_coef: 0.2740 - dice_coef: 0.3074 - val_loss: 0.2436 - val_accuracy: 0.9114 - val_iou_coef: 0.3878 - val_dice_coef: 0.4454\n",
      "Epoch 7/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1913 - accuracy: 0.9406 - iou_coef: 0.2778 - dice_coef: 0.3088\n",
      "Epoch 00007: val_loss improved from 0.22525 to 0.19401, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-2\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 498s 860ms/step - loss: 0.1915 - accuracy: 0.9406 - iou_coef: 0.2782 - dice_coef: 0.3091 - val_loss: 0.1940 - val_accuracy: 0.9301 - val_iou_coef: 0.4584 - val_dice_coef: 0.5017\n",
      "Epoch 8/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.9456 - iou_coef: 0.2876 - dice_coef: 0.3174\n",
      "Epoch 00008: val_loss improved from 0.19401 to 0.10993, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-2\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 498s 860ms/step - loss: 0.1802 - accuracy: 0.9457 - iou_coef: 0.2874 - dice_coef: 0.3173 - val_loss: 0.1099 - val_accuracy: 0.9586 - val_iou_coef: 0.5053 - val_dice_coef: 0.5424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9474 - iou_coef: 0.2966 - dice_coef: 0.3258\n",
      "Epoch 00009: val_loss did not improve from 0.10993\n",
      "579/579 [==============================] - 496s 857ms/step - loss: 0.1760 - accuracy: 0.9474 - iou_coef: 0.2965 - dice_coef: 0.3256 - val_loss: 0.2404 - val_accuracy: 0.9251 - val_iou_coef: 0.4529 - val_dice_coef: 0.4961\n",
      "Epoch 10/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1856 - accuracy: 0.9427 - iou_coef: 0.2855 - dice_coef: 0.3156\n",
      "Epoch 00010: val_loss did not improve from 0.10993\n",
      "579/579 [==============================] - 495s 855ms/step - loss: 0.1854 - accuracy: 0.9427 - iou_coef: 0.2855 - dice_coef: 0.3156 - val_loss: 0.2192 - val_accuracy: 0.9271 - val_iou_coef: 0.4412 - val_dice_coef: 0.4748\n",
      "Epoch 11/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1688 - accuracy: 0.9503 - iou_coef: 0.3012 - dice_coef: 0.3297\n",
      "Epoch 00011: val_loss did not improve from 0.10993\n",
      "579/579 [==============================] - 494s 854ms/step - loss: 0.1687 - accuracy: 0.9504 - iou_coef: 0.3012 - dice_coef: 0.3297 - val_loss: 0.3258 - val_accuracy: 0.9012 - val_iou_coef: 0.4274 - val_dice_coef: 0.4737\n",
      "Epoch 12/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1680 - accuracy: 0.9497 - iou_coef: 0.2975 - dice_coef: 0.3256\n",
      "Epoch 00012: val_loss did not improve from 0.10993\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "579/579 [==============================] - 493s 852ms/step - loss: 0.1678 - accuracy: 0.9497 - iou_coef: 0.2973 - dice_coef: 0.3254 - val_loss: 0.2000 - val_accuracy: 0.9405 - val_iou_coef: 0.4021 - val_dice_coef: 0.4368\n",
      "Epoch 13/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9555 - iou_coef: 0.3135 - dice_coef: 0.3381\n",
      "Epoch 00013: val_loss did not improve from 0.10993\n",
      "579/579 [==============================] - 493s 852ms/step - loss: 0.1506 - accuracy: 0.9555 - iou_coef: 0.3139 - dice_coef: 0.3385 - val_loss: 0.2165 - val_accuracy: 0.9354 - val_iou_coef: 0.4276 - val_dice_coef: 0.4616\n",
      "Epoch 14/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9563 - iou_coef: 0.3107 - dice_coef: 0.3349\n",
      "Epoch 00014: val_loss did not improve from 0.10993\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 0.1414 - accuracy: 0.9563 - iou_coef: 0.3109 - dice_coef: 0.3351 - val_loss: 0.2448 - val_accuracy: 0.9203 - val_iou_coef: 0.3947 - val_dice_coef: 0.4380\n",
      "Epoch 15/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1358 - accuracy: 0.9576 - iou_coef: 0.3151 - dice_coef: 0.3387\n",
      "Epoch 00015: val_loss did not improve from 0.10993\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 0.1365 - accuracy: 0.9574 - iou_coef: 0.3150 - dice_coef: 0.3387 - val_loss: 0.2083 - val_accuracy: 0.9370 - val_iou_coef: 0.4466 - val_dice_coef: 0.4865\n",
      "Epoch 16/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1337 - accuracy: 0.9578 - iou_coef: 0.3174 - dice_coef: 0.3405\n",
      "Epoch 00016: val_loss did not improve from 0.10993\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 0.1335 - accuracy: 0.9578 - iou_coef: 0.3180 - dice_coef: 0.3411 - val_loss: 0.2660 - val_accuracy: 0.9230 - val_iou_coef: 0.4550 - val_dice_coef: 0.4937\n",
      "Epoch 17/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1264 - accuracy: 0.9586 - iou_coef: 0.3223 - dice_coef: 0.3452\n",
      "Epoch 00017: val_loss did not improve from 0.10993\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 0.1263 - accuracy: 0.9587 - iou_coef: 0.3221 - dice_coef: 0.3450 - val_loss: 0.2460 - val_accuracy: 0.9141 - val_iou_coef: 0.4467 - val_dice_coef: 0.4888\n",
      "Epoch 18/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.9598 - iou_coef: 0.3171 - dice_coef: 0.3392\n",
      "Epoch 00018: val_loss did not improve from 0.10993\n",
      "579/579 [==============================] - 496s 856ms/step - loss: 0.1236 - accuracy: 0.9599 - iou_coef: 0.3172 - dice_coef: 0.3392 - val_loss: 0.2640 - val_accuracy: 0.8982 - val_iou_coef: 0.4196 - val_dice_coef: 0.4659\n",
      "Epoch 19/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1246 - accuracy: 0.9598 - iou_coef: 0.3235 - dice_coef: 0.3462\n",
      "Epoch 00019: val_loss did not improve from 0.10993\n",
      "579/579 [==============================] - 495s 854ms/step - loss: 0.1249 - accuracy: 0.9597 - iou_coef: 0.3234 - dice_coef: 0.3461 - val_loss: 0.2273 - val_accuracy: 0.9154 - val_iou_coef: 0.4676 - val_dice_coef: 0.5141\n",
      "Epoch 20/20\n",
      "578/579 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.9608 - iou_coef: 0.3224 - dice_coef: 0.3442\n",
      "Epoch 00020: val_loss did not improve from 0.10993\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "579/579 [==============================] - 495s 854ms/step - loss: 0.1215 - accuracy: 0.9607 - iou_coef: 0.3220 - dice_coef: 0.3437 - val_loss: 0.1877 - val_accuracy: 0.9247 - val_iou_coef: 0.4031 - val_dice_coef: 0.4446\n",
      "50/50 [==============================] - 16s 317ms/step - loss: 0.2676 - accuracy: 0.8924 - iou_coef: 0.4199 - dice_coef: 0.4670\n",
      "--- Starting trial: run-3\n",
      "{HParam(name='dropout', domain=Discrete([0.5, 0.7]), display_name=None, description=None): 0.7, HParam(name='layers', domain=Discrete([4, 5]), display_name=None, description=None): 5}\n",
      "{'dropout': 0.7, 'layers': 5}\n",
      "run-3 does not exist in D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\n",
      "model does not exist in D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-3\n",
      "dropout: 0.7\n",
      "num layers: 5\n",
      "Epoch 1/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.5876 - accuracy: 0.7211 - iou_coef: 0.0966 - dice_coef: 0.1524\n",
      "Epoch 00001: val_loss improved from inf to 0.82336, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-3\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 652s 1s/step - loss: 0.5877 - accuracy: 0.7210 - iou_coef: 0.0966 - dice_coef: 0.1524 - val_loss: 0.8234 - val_accuracy: 0.5219 - val_iou_coef: 0.1587 - val_dice_coef: 0.2446\n",
      "Epoch 2/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.5222 - accuracy: 0.7253 - iou_coef: 0.1122 - dice_coef: 0.1690\n",
      "Epoch 00002: val_loss improved from 0.82336 to 0.72149, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-3\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 653s 1s/step - loss: 0.5222 - accuracy: 0.7255 - iou_coef: 0.1121 - dice_coef: 0.1689 - val_loss: 0.7215 - val_accuracy: 0.5583 - val_iou_coef: 0.1402 - val_dice_coef: 0.2234\n",
      "Epoch 3/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.5228 - accuracy: 0.7310 - iou_coef: 0.1178 - dice_coef: 0.1736\n",
      "Epoch 00003: val_loss improved from 0.72149 to 0.66959, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-3\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 653s 1s/step - loss: 0.5230 - accuracy: 0.7307 - iou_coef: 0.1178 - dice_coef: 0.1736 - val_loss: 0.6696 - val_accuracy: 0.5281 - val_iou_coef: 0.2306 - val_dice_coef: 0.3304\n",
      "Epoch 4/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.3840 - accuracy: 0.8371 - iou_coef: 0.1806 - dice_coef: 0.2291\n",
      "Epoch 00004: val_loss improved from 0.66959 to 0.31884, saving model to D:PerlmutterData\\logs\\fit\\nucleus\\2020_02_03\\2020_02_03_09_07\\run-3\\model\\model_2020_02_03_09_07.h5\n",
      "579/579 [==============================] - 654s 1s/step - loss: 0.3836 - accuracy: 0.8373 - iou_coef: 0.1806 - dice_coef: 0.2291 - val_loss: 0.3188 - val_accuracy: 0.8853 - val_iou_coef: 0.3480 - val_dice_coef: 0.3974\n",
      "Epoch 5/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1978 - accuracy: 0.9375 - iou_coef: 0.2665 - dice_coef: 0.2977\n",
      "Epoch 00005: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1977 - accuracy: 0.9376 - iou_coef: 0.2664 - dice_coef: 0.2975 - val_loss: 0.4931 - val_accuracy: 0.8789 - val_iou_coef: 0.3604 - val_dice_coef: 0.3981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1906 - accuracy: 0.9410 - iou_coef: 0.2770 - dice_coef: 0.3063\n",
      "Epoch 00006: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1905 - accuracy: 0.9411 - iou_coef: 0.2770 - dice_coef: 0.3063 - val_loss: 0.5277 - val_accuracy: 0.8761 - val_iou_coef: 0.3096 - val_dice_coef: 0.3609\n",
      "Epoch 7/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1753 - accuracy: 0.9480 - iou_coef: 0.2840 - dice_coef: 0.3119\n",
      "Epoch 00007: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1752 - accuracy: 0.9480 - iou_coef: 0.2842 - dice_coef: 0.3120 - val_loss: 0.4826 - val_accuracy: 0.8956 - val_iou_coef: 0.3661 - val_dice_coef: 0.3952\n",
      "Epoch 8/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1703 - accuracy: 0.9499 - iou_coef: 0.2934 - dice_coef: 0.3201\n",
      "Epoch 00008: val_loss did not improve from 0.31884\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1702 - accuracy: 0.9499 - iou_coef: 0.2932 - dice_coef: 0.3200 - val_loss: 0.4585 - val_accuracy: 0.9017 - val_iou_coef: 0.3666 - val_dice_coef: 0.4008\n",
      "Epoch 9/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1504 - accuracy: 0.9548 - iou_coef: 0.3038 - dice_coef: 0.3286\n",
      "Epoch 00009: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1504 - accuracy: 0.9547 - iou_coef: 0.3035 - dice_coef: 0.3283 - val_loss: 0.4520 - val_accuracy: 0.9072 - val_iou_coef: 0.3988 - val_dice_coef: 0.4374\n",
      "Epoch 10/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1413 - accuracy: 0.9564 - iou_coef: 0.3068 - dice_coef: 0.3301\n",
      "Epoch 00010: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 648s 1s/step - loss: 0.1412 - accuracy: 0.9564 - iou_coef: 0.3070 - dice_coef: 0.3304 - val_loss: 0.5683 - val_accuracy: 0.8927 - val_iou_coef: 0.4369 - val_dice_coef: 0.4672\n",
      "Epoch 11/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1416 - accuracy: 0.9558 - iou_coef: 0.3048 - dice_coef: 0.3287\n",
      "Epoch 00011: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 649s 1s/step - loss: 0.1415 - accuracy: 0.9558 - iou_coef: 0.3048 - dice_coef: 0.3287 - val_loss: 0.3577 - val_accuracy: 0.9267 - val_iou_coef: 0.3938 - val_dice_coef: 0.4312\n",
      "Epoch 12/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1335 - accuracy: 0.9581 - iou_coef: 0.3127 - dice_coef: 0.3351\n",
      "Epoch 00012: val_loss did not improve from 0.31884\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "579/579 [==============================] - 648s 1s/step - loss: 0.1334 - accuracy: 0.9582 - iou_coef: 0.3124 - dice_coef: 0.3347 - val_loss: 0.4125 - val_accuracy: 0.8953 - val_iou_coef: 0.3806 - val_dice_coef: 0.4132\n",
      "Epoch 13/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1246 - accuracy: 0.9596 - iou_coef: 0.3144 - dice_coef: 0.3362\n",
      "Epoch 00013: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 648s 1s/step - loss: 0.1245 - accuracy: 0.9596 - iou_coef: 0.3146 - dice_coef: 0.3364 - val_loss: 0.4527 - val_accuracy: 0.8996 - val_iou_coef: 0.3866 - val_dice_coef: 0.4184\n",
      "Epoch 14/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1289 - accuracy: 0.9581 - iou_coef: 0.3097 - dice_coef: 0.3315\n",
      "Epoch 00014: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 648s 1s/step - loss: 0.1290 - accuracy: 0.9581 - iou_coef: 0.3095 - dice_coef: 0.3312 - val_loss: 0.4697 - val_accuracy: 0.8816 - val_iou_coef: 0.3647 - val_dice_coef: 0.3993\n",
      "Epoch 15/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1230 - accuracy: 0.9604 - iou_coef: 0.3185 - dice_coef: 0.3396\n",
      "Epoch 00015: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1232 - accuracy: 0.9604 - iou_coef: 0.3181 - dice_coef: 0.3392 - val_loss: 0.5463 - val_accuracy: 0.8763 - val_iou_coef: 0.4230 - val_dice_coef: 0.4562\n",
      "Epoch 16/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1259 - accuracy: 0.9594 - iou_coef: 0.3160 - dice_coef: 0.3373\n",
      "Epoch 00016: val_loss did not improve from 0.31884\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1257 - accuracy: 0.9594 - iou_coef: 0.3159 - dice_coef: 0.3372 - val_loss: 0.6307 - val_accuracy: 0.8574 - val_iou_coef: 0.4020 - val_dice_coef: 0.4426\n",
      "Epoch 17/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1265 - accuracy: 0.9589 - iou_coef: 0.3120 - dice_coef: 0.3336\n",
      "Epoch 00017: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1267 - accuracy: 0.9588 - iou_coef: 0.3118 - dice_coef: 0.3333 - val_loss: 0.4006 - val_accuracy: 0.8967 - val_iou_coef: 0.3557 - val_dice_coef: 0.3899\n",
      "Epoch 18/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1172 - accuracy: 0.9621 - iou_coef: 0.3158 - dice_coef: 0.3368\n",
      "Epoch 00018: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1175 - accuracy: 0.9621 - iou_coef: 0.3156 - dice_coef: 0.3366 - val_loss: 0.5966 - val_accuracy: 0.8759 - val_iou_coef: 0.3749 - val_dice_coef: 0.4070\n",
      "Epoch 19/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1245 - accuracy: 0.9588 - iou_coef: 0.3158 - dice_coef: 0.3371\n",
      "Epoch 00019: val_loss did not improve from 0.31884\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1244 - accuracy: 0.9589 - iou_coef: 0.3158 - dice_coef: 0.3371 - val_loss: 0.5203 - val_accuracy: 0.8749 - val_iou_coef: 0.4109 - val_dice_coef: 0.4477\n",
      "Epoch 20/20\n",
      "578/579 [============================>.] - ETA: 1s - loss: 0.1238 - accuracy: 0.9607 - iou_coef: 0.3129 - dice_coef: 0.3338\n",
      "Epoch 00020: val_loss did not improve from 0.31884\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "579/579 [==============================] - 647s 1s/step - loss: 0.1241 - accuracy: 0.9606 - iou_coef: 0.3130 - dice_coef: 0.3340 - val_loss: 0.4432 - val_accuracy: 0.8877 - val_iou_coef: 0.3815 - val_dice_coef: 0.4142\n",
      "50/50 [==============================] - 19s 374ms/step - loss: 0.5547 - accuracy: 0.8778 - iou_coef: 0.3702 - dice_coef: 0.4025\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "session_num = 0\n",
    "\n",
    "for dropout in HP_DROPOUT.domain.values:\n",
    "    for layer in HP_LAYERS.domain.values:\n",
    "        \n",
    "        run_name = \"run-{}\".format(session_num)\n",
    "        print('--- Starting trial: {}'.format(run_name))\n",
    "        \n",
    "        # create hyper-parameter\n",
    "        hparams = {\n",
    "            HP_DROPOUT: dropout,\n",
    "            HP_LAYERS: layer,\n",
    "        }\n",
    "        print(hparams)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "\n",
    "        # build model and traning\n",
    "        run(run_name, hparamtuning_dir, hparams)\n",
    "        \n",
    "        session_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "tfdl02",
   "language": "python",
   "name": "tfdl02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
